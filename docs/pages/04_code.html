<div class="content-middle">
    <h1>CODE</h1>
    <h2>Hot City, Heated Calls:<br>Analysis Notebooks</h2>
    
    <div class="notebook-controls">
        <button onclick="toggleAllCode(true)" class="code-toggle-btn">Show All Code</button>
        <button onclick="toggleAllCode(false)" class="code-toggle-btn">Hide All Code</button>
    </div>
    
    <div class="report-content notebook-content">

<div class="notebook-section" id="notebook-01a_weather_station_data_filtering">
    <h3 class="notebook-title">1a. Weather Station Data Filtering</h3>
    <p class="notebook-description">Filtering NOAA GSOD data to extract NYC weather stations (Central Park &amp; JFK).</p>
    <div class="notebook-cells">


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code>import os
os.getcwd()</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code>import tarfile
from pathlib import Path
import pandas as pd

# ===== 1. PATH TO YOUR GSOD YEAR FILE =====
# change this to your actual file, e.g. 2024.tar.gz or 2025.tar.gz
tar_path = Path(&quot;data/2025.tar.gz&quot;)

# ===== 2. BUILD A STATION TABLE FROM ALL CSVs =====
stations = []

with tarfile.open(tar_path, &quot;r:gz&quot;) as tar:
    for member in tar.getmembers():
        if not member.name.endswith(&quot;.csv&quot;):
            continue  # skip non-csv files

        f = tar.extractfile(member)
        if f is None:
            continue

        df_head = pd.read_csv(f, nrows=1)

        stations.append({
            &quot;file&quot;: member.name,
            &quot;STATION&quot;: df_head.get(&quot;STATION&quot;, [None])[0],
            &quot;NAME&quot;: df_head.get(&quot;NAME&quot;, [None])[0],
            &quot;LATITUDE&quot;: df_head.get(&quot;LATITUDE&quot;, [None])[0],
            &quot;LONGITUDE&quot;: df_head.get(&quot;LONGITUDE&quot;, [None])[0],
        })

stations_df = pd.DataFrame(stations)
print(&quot;Total stations in this year:&quot;, len(stations_df))

# ===== 3. FIND CANDIDATE NYC STATIONS =====
# (1) by rough lat/lon box around NYC
nyc_box = stations_df[
    (stations_df[&quot;LATITUDE&quot;].between(40.5, 41.1)) &amp;
    (stations_df[&quot;LONGITUDE&quot;].between(-74.3, -73.6))
]

print(&quot;\nStations in NYC bounding box:&quot;)
print(nyc_box[[&quot;file&quot;, &quot;STATION&quot;, &quot;NAME&quot;, &quot;LATITUDE&quot;, &quot;LONGITUDE&quot;]])

# (2) by name search (NEW YORK / CENTRAL PARK)
nyc_name = stations_df[
    stations_df[&quot;NAME&quot;].str.contains(&quot;NEW YORK|CENTRAL PARK&quot;, case=False, na=False)
]

print(&quot;\nStations with NEW YORK or CENTRAL PARK in name:&quot;)
print(nyc_name[[&quot;file&quot;, &quot;STATION&quot;, &quot;NAME&quot;, &quot;LATITUDE&quot;, &quot;LONGITUDE&quot;]])
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Total stations in this year: 11656

Stations in NYC bounding box:
                  file      STATION  \
7356   72055399999.csv  72055399999   
7370   72058100178.csv  72058100178   
8239   72409454743.csv  72409454743   
8436   72502014734.csv  72502014734   
8437   72502594741.csv  72502594741   
8441   72503014732.csv  72503014732   
8443   72503794745.csv  72503794745   
8450   72505394728.csv  72505394728   
9077   74486094789.csv  74486094789   
11179  99727199999.csv  99727199999   
11186  99728099999.csv  99728099999   
11273  99774399999.csv  99774399999   

                                                NAME   LATITUDE  LONGITUDE  
7356   PORT AUTH DOWNTN MANHATTAN WALL ST HEL, NY US  40.701214 -74.009028  
7370                           LINDEN AIRPORT, NJ US  40.617000 -74.250000  
8239                CALDWELL ESSEX CO AIRPORT, NJ US  40.876450 -74.282840  
8436     NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  40.682750 -74.169270  
8437                        TETERBORO AIR
... [truncated]</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code>import tarfile
import pandas as pd
from pathlib import Path

# ========== You already have these ==========
# stations_df  â†’ a DataFrame containing columns: file, STATION, NAME, LATITUDE, LONGITUDE
# tar_path     â†’ path to 2024.tar.gz (or 2025.tar.gz)

# Directory to save selected station csv
output_dir = Path(&quot;data/nyc_two_stations&quot;)
output_dir.mkdir(exist_ok=True)
</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code># Central Park
cp_row = stations_df[
    stations_df[&quot;NAME&quot;].str.contains(&quot;NY CITY CENTRAL PARK&quot;, case=False, na=False)
].iloc[0]

# JFK
jfk_row = stations_df[
    stations_df[&quot;NAME&quot;].str.contains(&quot;JFK INTERNATIONAL AIRPORT&quot;, case=False, na=False)
].iloc[0]

cp_file = cp_row[&quot;file&quot;]
jfk_file = jfk_row[&quot;file&quot;]

print(&quot;Central Park file:&quot;, cp_file)
print(&quot;JFK file:&quot;, jfk_file)
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Central Park file: 72505394728.csv
JFK file: 74486094789.csv
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code>def read_csv_from_tar(tar_path, csv_file_name):
    with tarfile.open(tar_path, &quot;r:gz&quot;) as tar:
        f = tar.extractfile(csv_file_name)
        return pd.read_csv(f)

cp_data = read_csv_from_tar(tar_path, cp_file)
jfk_data = read_csv_from_tar(tar_path, jfk_file)

cp_out = output_dir / &quot;NYC_Central_Park.csv&quot;
jfk_out = output_dir / &quot;NYC_JFK_Airport.csv&quot;

cp_data.to_csv(cp_out, index=False)
jfk_data.to_csv(jfk_out, index=False)

print(&quot;Saved:&quot;, cp_out)
print(&quot;Saved:&quot;, jfk_out)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved: data\nyc_two_stations\NYC_Central_Park.csv
Saved: data\nyc_two_stations\NYC_JFK_Airport.csv
</pre>
</div>
</div>

</div></div>

<div class="notebook-section" id="notebook-01b_extreme_heat_days_filter">
    <h3 class="notebook-title">1b. Extreme Heat Days Classification</h3>
    <p class="notebook-description">Classifying days as extreme heat (â‰¥93Â°F) vs normal heat based on climatological thresholds.</p>
    <div class="notebook-cells">

<div class="cell-markdown"><p><h5>Calculate Threshold from Benchmark Period 1981-2010</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code>import tarfile
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ----------------- CONFIGURATION -----------------
DATA_DIR = Path(&quot;data/History weather station data&quot;)               # relative path to data folder
YEARS = range(1981, 2011)             # baseline period: 1981â€“2010
STATION_FILENAME = &quot;data/74486094789.csv&quot;  # JFK station file name
# -------------------------------------------------

all_max_temps = []  # store all summer daily max temperatures

for year in YEARS:
    tar_path = DATA_DIR / f&quot;{year}.tar.gz&quot;
    if not tar_path.exists():
        print(f&quot;[WARN] {tar_path} does not exist, skipped.&quot;)
        continue

    print(f&quot;[INFO] Processing {tar_path} ...&quot;)
    with tarfile.open(tar_path, &quot;r:gz&quot;) as tar:
        jfk_member = None
        for member in tar.getmembers():
            # the file may be inside a subfolder, so check only filename ending
            if member.name.endswith(STATION_FILENAME):
                jfk_member = member
                break

        if jfk_member is None:
            print(f&quot;[WARN] {STATION_FILENAME} not found in {tar_path}, skipped.&quot;)
            continue

        # extract the CSV file directly from tar.gz
        f = tar.extractfile(jfk_member)
        if f is None:
            print(f&quot;[WARN] Could not extract {STATION_FILENAME} from {tar_path}&quot;)
            continue

        # ignore possible header comment lines starting with &quot;#&quot;
        df = pd.read_csv(f, comment=&quot;#&quot;)

        # unify column names to uppercase
        df.columns = [c.upper() for c in df.columns]

        # DATE column required
        if &quot;DATE&quot; not in df.columns:
            raise ValueError(f&quot;DATE column not found in {STATION_FILENAME}&quot;)

        df[&quot;DATE&quot;] = pd.to_datetime(df[&quot;DATE&quot;])

        # keep only Juneâ€“August (JJA)
        df_summer = df[df[&quot;DATE&quot;].dt.month.isin([6, 7, 8])].copy()

        # find temperature column: MAX or TMAX
        temp_col = None
        if &quot;MAX&quot; in df_summer.columns:
            temp_col = &quot;MAX&quot;
        elif &quot;TMAX&quot; in df_summer.columns:
            temp_col = &quot;TMAX&quot;
        else:
            raise ValueError(f&quot;MAX/TMAX column not found in {STATION_FILENAME}&quot;)

        temps = pd.to_numeric(df_summer[temp_col], errors=&quot;coerce&quot;)

        # replace missing codes like 9999/99999 with NaN then remove them
        temps = temps.replace([9999, 99999, 999.9, 99.9], np.nan)
        temps = temps.dropna()

        all_max_temps.append(temps)

# merge all years into a single Series
if not all_max_temps:
    raise RuntimeError(&quot;No valid temperature data found. Check file names and structure.&quot;)

all_max_temps = pd.concat(all_max_temps, ignore_index=True)

# NOTE: temperatures are already Fahrenheit â†’ do NOT convert
# (NO scaling applied)

# compute 95th percentile in Fahrenheit
p95_f = np.percentile(all_max_temps, 95)
p90_f = np.percentile(all_max_temps, 90)

print(f&quot;1981â€“2010 JFK JJA daily max temperature 95th percentile:&quot;)
print(f&quot;  {p95_f:.2f} Â°F&quot;)
print(f&quot;  {p90_f:.2f} Â°F&quot;)

# ---------- plot histogram ----------
plt.figure(figsize=(8, 5))
plt.hist(all_max_temps, bins=40)
plt.axvline(p95_f, linestyle=&quot;--&quot;, linewidth=2)
plt.xlabel(&quot;Daily max temperature (Â°F)&quot;)
plt.ylabel(&quot;Frequency&quot;)
plt.title(&quot;JFK 1981â€“2010 JJA daily max temperature\nwith 95th percentile&quot;)
plt.tight_layout()
plt.show()

# Save result to csv
all_max_temps.to_csv(&quot;jfk_summer_jja_1981_2010_tmax.csv&quot;, index=False, header=[&quot;TMAX_C&quot;])</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">[INFO] Processing data\History weather station data\1981.tar.gz ...
[INFO] Processing data\History weather station data\1982.tar.gz ...
[INFO] Processing data\History weather station data\1983.tar.gz ...
[INFO] Processing data\History weather station data\1984.tar.gz ...
[INFO] Processing data\History weather station data\1985.tar.gz ...
[INFO] Processing data\History weather station data\1986.tar.gz ...
[INFO] Processing data\History weather station data\1987.tar.gz ...
[INFO] Processing data\History weather station data\1988.tar.gz ...
[INFO] Processing data\History weather station data\1989.tar.gz ...
[INFO] Processing data\History weather station data\1990.tar.gz ...
[INFO] Processing data\History weather station data\1991.tar.gz ...
[INFO] Processing data\History weather station data\1992.tar.gz ...
[INFO] Processing data\History weather station data\1993.tar.gz ...
[INFO] Processing data\History weather station data\1994.tar.gz ...
[INFO] Processing data\History weather station d
... [truncated]</pre>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>Filter 2025 summer NYC</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code>import numpy as np
import pandas as pd
from pathlib import Path

# 95th percentile threshold from baseline (1981â€“2010)
THRESHOLD_F = 91.0

# path to 2025 JFK data
csv_path = Path(&quot;data/nyc_two_stations/NYC_JFK_Airport.csv&quot;)

# read CSV
df = pd.read_csv(csv_path)

# unify column names to uppercase
df.columns = [c.upper() for c in df.columns]

# parse DATE column
if &quot;DATE&quot; not in df.columns:
    raise ValueError(&quot;DATE column not found in NYC_JFK_Airport.csv&quot;)

df[&quot;DATE&quot;] = pd.to_datetime(df[&quot;DATE&quot;])

# keep only year 2025
df_2025 = df[df[&quot;DATE&quot;].dt.year == 2025].copy()

# keep only Juneâ€“August (JJA)
df_jja = df_2025[df_2025[&quot;DATE&quot;].dt.month.isin([6, 7, 8])].copy()

# find max temperature column (Fahrenheit)
temp_col = None
if &quot;MAX&quot; in df_jja.columns:
    temp_col = &quot;MAX&quot;
elif &quot;TMAX&quot; in df_jja.columns:
    temp_col = &quot;TMAX&quot;
else:
    raise ValueError(&quot;MAX/TMAX column not found in NYC_JFK_Airport.csv&quot;)

# clean temperature values
temps = pd.to_numeric(df_jja[temp_col], errors=&quot;coerce&quot;)
temps = temps.replace([9999, 99999, 999.9, 99.9], np.nan)
df_jja[&quot;TMAX_F&quot;] = temps
df_jja = df_jja.dropna(subset=[&quot;TMAX_F&quot;])

# classify extreme heat days (&gt;= 95th percentile threshold)
df_jja[&quot;EXTREME_HEAT&quot;] = np.where(df_jja[&quot;TMAX_F&quot;] &gt;= THRESHOLD_F, &quot;yes&quot;, &quot;no&quot;)

# ---------- print summary ----------
total_yes = (df_jja[&quot;EXTREME_HEAT&quot;] == &quot;yes&quot;).sum()
total_no = (df_jja[&quot;EXTREME_HEAT&quot;] == &quot;no&quot;).sum()

print(&quot;JFK 2025 JJA extreme heat classification (threshold = 93Â°F)&quot;)
print(f&quot;  Extreme heat days (yes): {total_yes}&quot;)
print(f&quot;  Non-extreme days (no):   {total_no}&quot;)

# counts by month
month_label = df_jja[&quot;DATE&quot;].dt.month
crosstab = pd.crosstab(month_label, df_jja[&quot;EXTREME_HEAT&quot;])

print(&quot;\nExtreme heat days by month (JJA 2025):&quot;)
print(crosstab)   # rows: month (6,7,8), columns: yes/no

# ---------- save CSV ----------
# keep only JJA, with date, max temp (Â°F), and extreme heat flag
output = df_jja[[&quot;DATE&quot;, &quot;TMAX_F&quot;, &quot;EXTREME_HEAT&quot;]].copy()
output = output.sort_values(&quot;DATE&quot;)

output.to_csv(&quot;JFK_2025_JJA_extreme_heat_90.csv&quot;, index=False)
print(&quot;\nSaved JJA 2025 classification to: JFK_2025_JJA_extreme_heat_90.csv&quot;)
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">JFK 2025 JJA extreme heat classification (threshold = 93Â°F)
  Extreme heat days (yes): 17
  Non-extreme days (no):   71

Extreme heat days by month (JJA 2025):
EXTREME_HEAT  no  yes
DATE                 
6             24    6
7             20   11
8             27    0

Saved JJA 2025 classification to: JFK_2025_JJA_extreme_heat_90.csv
</pre>
</div>
</div>

</div></div>

<div class="notebook-section" id="notebook-02_311_tract_daily">
    <h3 class="notebook-title">2. NYC 311 Data Processing</h3>
    <p class="notebook-description">Processing 311 service requests and aggregating QoL complaints by census tract.</p>
    <div class="notebook-cells">

<div class="cell-markdown"><p><h5>311 QUALITY OF LIFE BY TRACTS (SUMMER, 2025)</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code># Modules.
import pandas as pd
import geopandas as gpd
import numpy as np
from shapely.geometry import Point
import requests, time
from pathlib import Path</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code># Paths.
nyc_311_dir = Path(&quot;data/nyc_311&quot;)
nyc_311 = nyc_311_dir / &quot;311_raw&quot;
nyc_311.mkdir(parents = True, exist_ok = True)

# NYC 2020 census tracts shapefile.
tracts_path = Path(&quot;data/nyc_tracts_2020/nyc_tracts_2020.shp&quot;)

# Output.
raw_path = nyc_311 / &quot;nyc_311_summer_2025.csv&quot;
panel_path = nyc_311_dir / &quot;nyc_311_tract_day_2025.csv&quot;
point_path_geojson = nyc_311_dir / &quot;nyc_311_points_2025.geojson&quot;</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code># Noise &amp; Social Activity (heat-sensitive)
QOL_NOISE = [
    &quot;LOUD MUSIC/PARTY&quot;, &quot;BANGING/POUNDING&quot;, &quot;LOUD TALKING&quot;,
    &quot;CAR/TRUCK MUSIC&quot;, &quot;CAR/TRUCK HORN&quot;, &quot;DOG NOISE&quot;,
    &quot;NOISE: BOAT(ENGINE,MUSIC,ETC) (NR10)&quot;,
    &quot;NOISE: ALARMS (NR3)&quot;,
    &quot;NOISE: AIR CONDITION/VENTILATION EQUIPMENT (NV1)&quot;,
    &quot;NOISE: CONSTRUCTION BEFORE/AFTER HOURS (NM1)&quot;,
    &quot;NOISE: JACK HAMMERING (NC2)&quot;,
    &quot;NOISE, BARKING DOG (NR5)&quot;,
    &quot;NOISE: MANUFACTURING NOISE (NK1)&quot;,
    &quot;NOISE: OTHER NOISE SOURCES (USE COMMENTS) (NZZ)&quot;
]

# Outdoor Activity / Public Space Use
QOL_OUTDOOR = [
    &quot;BLOCKED HYDRANT&quot;, &quot;BLOCKED SIDEWALK&quot;, &quot;BLOCKED BIKE LANE&quot;,
    &quot;ILLEGAL PARKING&quot;, &quot;DOUBLE PARKED BLOCKING TRAFFIC&quot;,
    &quot;BLOCKED CROSSWALK&quot;, &quot;DERELICT VEHICLES&quot;, &quot;CONGESTION/GRIDLOCK&quot;,
    &quot;GRAFFITI&quot;, &quot;CHRONIC DUMPING&quot;,
    &quot;COMMERCIAL OVERNIGHT PARKING&quot;
]

# Sanitation, Trash, Pests
QOL_SANITATION = [
    &quot;GARBAGE OR LITTER&quot;, &quot;TRASH&quot;, &quot;OVERFLOWING&quot;,
    &quot;RAT SIGHTING&quot;, &quot;MOUSE SIGHTING&quot;, &quot;CONDITION ATTRACTING RODENTS&quot;,
    &quot;PESTS&quot;, &quot;UNSANITARY CONDITION&quot;, &quot;DEAD ANIMAL&quot;,
    &quot;WASTE DISPOSAL&quot;, &quot;DOG WASTE&quot;
]

# Water Infrastructure &amp; Hydrants
QOL_WATER = [
    &quot;WATER LEAK&quot;, &quot;WATER SUPPLY&quot;, &quot;HYDRANT LEAKING (WC1)&quot;,
    &quot;HYDRANT RUNNING FULL (WA4)&quot;, &quot;HYDRANT RUNNING (WC3)&quot;,
    &quot;HYDRANT DEFECTIVE (WC2)&quot;, &quot;SEWER&quot;, &quot;SEWER ODOR (SA2)&quot;,
    &quot;SEWER BACKUP (SA)&quot;, &quot;LEAK (USE COMMENTS) (WA2)&quot;
]

# Infrastructure Heat Stress
QOL_INFRA_HEAT = [
    &quot;POWER OUTAGE&quot;, &quot;ELECTRICAL/GAS RANGE&quot;, &quot;VENTILATION SYSTEM&quot;,
    &quot;TRAFFIC SIGNAL LIGHT&quot;, &quot;STREET LIGHT OUT&quot;, 
    &quot;STREET LIGHT LAMP MISSING&quot;, &quot;STREET LIGHT CYCLING&quot;
]</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code># Build lookup dictionary for mapping.
def build_qol_lookup():
    mapping = {}
    for c in QOL_NOISE: mapping[c] = &quot;QOL_NOISE&quot;
    for c in QOL_OUTDOOR: mapping[c] = &quot;QOL_OUTDOOR&quot;
    for c in QOL_SANITATION: mapping[c] = &quot;QOL_SANITATION&quot;
    for c in QOL_WATER: mapping[c] = &quot;QOL_WATER_INFRA&quot;
    for c in QOL_INFRA_HEAT: mapping[c] = &quot;QOL_INFRA_HEAT&quot;
    return mapping

QOL_LOOKUP = build_qol_lookup()</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code># Download helper.
def download_311_jfk_2025(token = None):
    base = &quot;https://data.cityofnewyork.us/resource/erm2-nwe9.json&quot;
    headers = {&quot;X-App-Token&quot;: token} if token else {}
    limit = 50000

    start = &quot;2025-06-01T00:00:00&quot;
    end = &quot;2025-08-22T23:59:59&quot;

    where_clause = (
        f&quot;created_date between &#x27;{start}&#x27; and &#x27;{end}&#x27; &quot;
        &quot;AND latitude IS NOT NULL AND longitude IS NOT NULL&quot;
    )

    cols = [
        &quot;unique_key&quot;, &quot;created_date&quot;, &quot;complaint_type&quot;,
        &quot;descriptor&quot;, &quot;latitude&quot;, &quot;longitude&quot;, &quot;borough&quot;
    ]

    offset = 0
    frames = []

    while True:
        params = {
            &quot;$select&quot;: &quot;,&quot;.join(cols),
            &quot;$where&quot;: where_clause,
            &quot;$limit&quot;: limit,
            &quot;$offset&quot;: offset,
            &quot;$order&quot;: &quot;created_date&quot;
        }
        r = requests.get(base, params = params, headers = headers)
        data = r.json()
        if len(data) == 0:
            break

        frames.append(pd.DataFrame(data))
        print(&quot;Fetched:&quot;, len(data), &quot;offset:&quot;, offset)
        offset += limit
        time.sleep(0.3)

    df = pd.concat(frames, ignore_index = True)
    df.to_csv(raw_path, index = False)

    print(&quot;Saved:&quot;, raw_path)
    return df</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 6</summary>
        <pre class="cell-code"><code># Download.
calls_311 = download_311_jfk_2025(token = None)
calls_311[&quot;created_date&quot;] = pd.to_datetime(calls_311[&quot;created_date&quot;], errors = &quot;coerce&quot;)
calls_311[&quot;latitude&quot;] = pd.to_numeric(calls_311[&quot;latitude&quot;])
calls_311[&quot;longitude&quot;] = pd.to_numeric(calls_311[&quot;longitude&quot;])</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Fetched: 50000 offset: 0
Fetched: 50000 offset: 50000
Fetched: 50000 offset: 100000
Fetched: 50000 offset: 150000
Fetched: 50000 offset: 200000
Fetched: 50000 offset: 250000
Fetched: 50000 offset: 300000
Fetched: 50000 offset: 350000
Fetched: 50000 offset: 400000
Fetched: 50000 offset: 450000
Fetched: 50000 offset: 500000
Fetched: 50000 offset: 550000
Fetched: 50000 offset: 600000
Fetched: 50000 offset: 650000
Fetched: 26191 offset: 700000
Saved: data\nyc_311\311_raw\nyc_311_summer_2025.csv
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 7</summary>
        <pre class="cell-code"><code># Spatial join to tracts.
gdf_tracts = gpd.read_file(tracts_path)

nyc_prefixes = (&quot;36005&quot;, &quot;36047&quot;, &quot;36061&quot;, &quot;36081&quot;, &quot;36085&quot;)
gdf_tracts = gdf_tracts[gdf_tracts[&quot;geoid&quot;].str.startswith(nyc_prefixes)].copy()

gdf_311 = gpd.GeoDataFrame(
    calls_311,
    geometry=[Point(xy) for xy in zip(calls_311.longitude, calls_311.latitude)],
    crs = &quot;EPSG:4326&quot;
).to_crs(gdf_tracts.crs)

joined_gdf = gpd.sjoin(
    gdf_311,
    gdf_tracts[[&quot;geoid&quot;,&quot;geometry&quot;]],
    how = &quot;left&quot;,
    predicate = &quot;within&quot;
)

joined_gdf = joined_gdf.dropna(subset = [&quot;geoid&quot;]).copy()
joined_gdf.rename(columns = {&quot;geoid&quot;:&quot;GEOID&quot;}, inplace = True)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 8</summary>
        <pre class="cell-code"><code># Encode to QoL superclasses.
joined_gdf[&quot;ct_norm&quot;] = joined_gdf[&quot;complaint_type&quot;].str.upper().str.strip()
joined_gdf[&quot;qol_category&quot;] = joined_gdf[&quot;ct_norm&quot;].map(QOL_LOOKUP)

# Heat-relevant QoL calls.
joined_gdf[&quot;is_heat_qol&quot;] = joined_gdf[&quot;qol_category&quot;].notna()

# Build tract by day.
joined_gdf[&quot;date&quot;] = joined_gdf[&quot;created_date&quot;].dt.date

panel = (
    joined_gdf.groupby([&quot;GEOID&quot;,&quot;date&quot;], as_index = False)
    .agg(
        total_calls = (&quot;unique_key&quot;, &quot;count&quot;),
        qol_calls = (&quot;is_heat_qol&quot;, &quot;sum&quot;),
        #mean_latitude = (&quot;latitude&quot;, &quot;mean&quot;),
        #mean_longitude = (&quot;longitude&quot;, &quot;mean&quot;)
    )
)

panel[&quot;heat_qol_rate_1k&quot;] = (panel[&quot;qol_calls&quot;].astype(float))

panel[&quot;qol_pct&quot;] = np.where(
    panel[&quot;total_calls&quot;] &gt; 0,
    panel[&quot;qol_calls&quot;]/panel[&quot;total_calls&quot;],
    np.nan
)

panel.columns = panel.columns.str.upper()</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 9</summary>
        <pre class="cell-code"><code>panel.to_csv(panel_path, index = False)
print(&quot;Saved panel:&quot;, panel_path)

panel</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved panel: data/nyc_311/panel/nyc_311_tract_day_2025.csv
</pre>
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GEOID</th>
      <th>DATE</th>
      <th>TOTAL_CALLS</th>
      <th>QOL_CALLS</th>
      <th>HEAT_QOL_RATE_1K</th>
      <th>QOL_PCT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36005000100</td>
      <td>2025-06-30</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36005000100</td>
      <td>2025-07-23</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36005000100</td>
      <td>2025-08-04</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36005000200</td>
      <td>2025-06-01</td>
      <td>8</td>
      <td>5</td>
      <td>5.0</td>
      <td>0.625</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36005000200</td>
      <td>2025-06-02</td>
      <td>3</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>162339</th>
      <td>36085032300</td>
      <td>2025-08-15</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>162340</th>
      <td>36085032300</td>
      <td>2025-08-18</td>
      <td>2</td>
      <td>1</td>
      <td>1.0</td>
      <td>0.500</td>
    </tr>
    <tr>
      <th>162341</th>
      <td>36085032300</td>
      <td>2025-08-19</td>
      <td>4</td>
      <td>4</td>
      <td>4.0</td>
      <td>1.000</td>
    </tr>
    <tr>
      <th>162342</th>
      <td>36085032300</td>
      <td>2025-08-20</td>
      <td>2</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>162343</th>
      <td>36085032300</td>
      <td>2025-08-21</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table>
<p>162344 rows Ã— 6 columns</p>
</div></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 10</summary>
        <pre class="cell-code"><code># Save point aggregated data joined_gdf with GEOID assignment.
point_cols = [
    &quot;unique_key&quot;, &quot;created_date&quot;, &quot;complaint_type&quot;, &quot;descriptor&quot;,
    &quot;latitude&quot;, &quot;longitude&quot;, &quot;borough&quot;, &quot;GEOID&quot;, 
    &quot;ct_norm&quot;, &quot;qol_flag&quot;, &quot;date&quot;, &quot;geometry&quot;
]

# Ensure only the necessary columns are kept and the index is dropped for clean output.
point_data_gdf = joined_gdf[point_cols].copy()

# Save GeoDataFrame to GeoJSON file.
point_data_gdf.to_file(point_path_geojson, driver = &quot;GeoJSON&quot;)

print(&quot;Saved point data as GeoJSON:&quot;, point_path_geojson)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved point data as GeoJSON: data\nyc_311\nyc_311_points_2025.geojson
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 11</summary>
        <pre class="cell-code"><code># # 311 tract-by-day panel with full QoL categories.
# # Counts, % shares, and per-capita rates (per 1,000).

# joined_gdf[&quot;date&quot;] = joined_gdf[&quot;created_date&quot;].dt.date

# joined_gdf[&quot;is_noise&quot;]        = joined_gdf[&quot;qol_category&quot;].eq(&quot;QOL_NOISE&quot;)
# joined_gdf[&quot;is_outdoor&quot;]      = joined_gdf[&quot;qol_category&quot;].eq(&quot;QOL_OUTDOOR&quot;)
# joined_gdf[&quot;is_sanitation&quot;]   = joined_gdf[&quot;qol_category&quot;].eq(&quot;QOL_SANITATION&quot;)
# joined_gdf[&quot;is_water&quot;]        = joined_gdf[&quot;qol_category&quot;].eq(&quot;QOL_WATER_INFRA&quot;)
# joined_gdf[&quot;is_infra_heat&quot;]   = joined_gdf[&quot;qol_category&quot;].eq(&quot;QOL_INFRA_HEAT&quot;)

# # Counts.
# panel = (
#     joined_gdf.groupby([&quot;GEOID&quot;, &quot;date&quot;], as_index=False)
#     .agg(
#         total_calls     = (&quot;unique_key&quot;, &quot;count&quot;),
#         qol_noise       = (&quot;is_noise&quot;, &quot;sum&quot;),
#         qol_outdoor     = (&quot;is_outdoor&quot;, &quot;sum&quot;),
#         qol_sanitation  = (&quot;is_sanitation&quot;, &quot;sum&quot;),
#         qol_water       = (&quot;is_water&quot;, &quot;sum&quot;),
#         qol_infra_heat  = (&quot;is_infra_heat&quot;, &quot;sum&quot;)
#     )
# )

# # Total calls.
# panel[&quot;qol_calls&quot;] = (
#       panel[&quot;qol_noise&quot;]
#     + panel[&quot;qol_outdoor&quot;]
#     + panel[&quot;qol_sanitation&quot;]
#     + panel[&quot;qol_water&quot;]
#     + panel[&quot;qol_infra_heat&quot;]
# )

# # Percent calls.
# def pct(col):
#     return np.where(panel[&quot;total_calls&quot;] &gt; 0, panel[col] / panel[&quot;total_calls&quot;], np.nan)

# panel[&quot;qol_pct&quot;]             = pct(&quot;qol_calls&quot;)
# panel[&quot;qol_noise_pct&quot;]       = pct(&quot;qol_noise&quot;)
# panel[&quot;qol_outdoor_pct&quot;]     = pct(&quot;qol_outdoor&quot;)
# panel[&quot;qol_sanitation_pct&quot;]  = pct(&quot;qol_sanitation&quot;)
# panel[&quot;qol_water_pct&quot;]       = pct(&quot;qol_water&quot;)
# panel[&quot;qol_infra_heat_pct&quot;]  = pct(&quot;qol_infra_heat&quot;)

# # Per-capita rate variables (calls per 1,000 population).
# # IMPORTANT: ACS merge must happen AFTER this panel is created.
# # This step stubs the columns but they will compute AFTER merging.

# # Create empty rate columns now; fill after ACS merge.
# panel[&quot;qol_rate_1k&quot;]             = np.nan
# panel[&quot;qol_noise_rate_1k&quot;]       = np.nan
# panel[&quot;qol_outdoor_rate_1k&quot;]     = np.nan
# panel[&quot;qol_sanitation_rate_1k&quot;]  = np.nan
# panel[&quot;qol_water_rate_1k&quot;]       = np.nan
# panel[&quot;qol_infra_heat_rate_1k&quot;]  = np.nan

# # Final column order.
# panel = panel[
#     [
#         &quot;GEOID&quot;, &quot;date&quot;,
#         &quot;total_calls&quot;, &quot;qol_calls&quot;, &quot;qol_pct&quot;,
#         &quot;qol_noise&quot;, &quot;qol_outdoor&quot;, &quot;qol_sanitation&quot;,
#         &quot;qol_water&quot;, &quot;qol_infra_heat&quot;,
#         &quot;qol_noise_pct&quot;, &quot;qol_outdoor_pct&quot;,
#         &quot;qol_sanitation_pct&quot;, &quot;qol_water_pct&quot;,
#         &quot;qol_infra_heat_pct&quot;,
#         # Rate variables for later ACS merge.
#         &quot;qol_rate_1k&quot;,
#         &quot;qol_noise_rate_1k&quot;,
#         &quot;qol_outdoor_rate_1k&quot;,
#         &quot;qol_sanitation_rate_1k&quot;,
#         &quot;qol_water_rate_1k&quot;,
#         &quot;qol_infra_heat_rate_1k&quot;
#     ]
# ]

# panel.to_csv(panel_path, index = False)
# print(&quot;Saved panel:&quot;, panel_path)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 12</summary>
        <pre class="cell-code"><code># # ACS merge guide.
# df = panel.merge(acs[[&quot;GEOID&quot;,&quot;TOTAL_POP&quot;]], on=&quot;GEOID&quot;, how=&quot;left&quot;)

# # Per 1,000 rates.
# df[&quot;qol_rate_1k&quot;]            = (df[&quot;qol_calls&quot;]       / df[&quot;TOTAL_POP&quot;]) * 1000
# df[&quot;qol_noise_rate_1k&quot;]      = (df[&quot;qol_noise&quot;]       / df[&quot;TOTAL_POP&quot;]) * 1000
# df[&quot;qol_outdoor_rate_1k&quot;]    = (df[&quot;qol_outdoor&quot;]     / df[&quot;TOTAL_POP&quot;]) * 1000
# df[&quot;qol_sanitation_rate_1k&quot;] = (df[&quot;qol_sanitation&quot;]  / df[&quot;TOTAL_POP&quot;]) * 1000
# df[&quot;qol_water_rate_1k&quot;]      = (df[&quot;qol_water&quot;]       / df[&quot;TOTAL_POP&quot;]) * 1000
# df[&quot;qol_infra_heat_rate_1k&quot;] = (df[&quot;qol_infra_heat&quot;]  / df[&quot;TOTAL_POP&quot;]) * 1000</code></pre>
    </details>
    
</div>

</div></div>

<div class="notebook-section" id="notebook-03_acs_tract">
    <h3 class="notebook-title">3. Census ACS Data</h3>
    <p class="notebook-description">Extracting socioeconomic indicators from American Community Survey at tract level.</p>
    <div class="notebook-cells">

<div class="cell-markdown"><p><h5>5-YEAR ACS SOCIOECONOMIC DATA BY TRACTS (2022)</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code># Modules.
import cenpy
import pandas as pd
import geopandas as gpd
import numpy as np
from pathlib import Path
import pygris</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code># Paths.
acs_dir = Path(&quot;data/acs&quot;)
acs_dir.mkdir(parents = True, exist_ok = True)

output_file = acs_dir / &quot;acs_socioeconomic_tract_2022.csv&quot;</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code># Connect to ACS 2022 5-year table.
api = cenpy.remote.APIConnection(&quot;ACSDT5Y2022&quot;)

# NYC counties.
nyc_counties = [&quot;005&quot;, &quot;047&quot;, &quot;061&quot;, &quot;081&quot;, &quot;085&quot;]

# ACS variables.
acs_variables = {
    # Core.
    &quot;total_pop&quot;: &quot;B01003_001E&quot;,
    &quot;median_income&quot;: &quot;B19013_001E&quot;,
    &quot;poverty_all&quot;: &quot;B17001_001E&quot;,
    &quot;poverty_count&quot;: &quot;B17001_002E&quot;,
    &quot;no_vehicle_hh&quot;: &quot;B25044_003E&quot;,
    &quot;white&quot;: &quot;B02001_002E&quot;,

    # Education.
    &quot;edu_bachelors&quot;: &quot;B15003_022E&quot;,
    &quot;edu_masters&quot;: &quot;B15003_023E&quot;,
    &quot;edu_professional&quot;: &quot;B15003_024E&quot;,
    &quot;edu_doctorate&quot;: &quot;B15003_025E&quot;,
    &quot;edu_total&quot;: &quot;B15003_001E&quot;,

    # Housing tenure.
    &quot;owner_hh&quot;: &quot;B25003_002E&quot;,
    &quot;renter_hh&quot;: &quot;B25003_003E&quot;,
    &quot;hh_total&quot;: &quot;B25003_001E&quot;,

    # Limited English.
    &quot;limited_english&quot;: &quot;B16005_007E&quot;, 
    &quot;limited_english_total&quot;: &quot;B16005_001E&quot;
}

cols = [&quot;NAME&quot;] + list(acs_variables.values())</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code># Download ACS for all NYC counties at the tract level.
records = []

for county in nyc_counties:
    print(f&quot;Downloading ACS for county {county}.&quot;)

    df = api.query(
        cols = cols,
        geo_unit = &quot;tract&quot;,
        geo_filter = {&quot;state&quot;: &quot;36&quot;, &quot;county&quot;: county}
    )

    records.append(df)

acs = pd.concat(records, ignore_index = True)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Downloading ACS for county 005.
Downloading ACS for county 047.
Downloading ACS for county 061.
Downloading ACS for county 081.
Downloading ACS for county 085.
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code># Construct GEOID.
acs[&quot;GEOID&quot;] = acs[&quot;state&quot;] + acs[&quot;county&quot;] + acs[&quot;tract&quot;]</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 6</summary>
        <pre class="cell-code"><code># Rename ACS columns.
rename_map = {v: k for k, v in acs_variables.items()}

acs = acs.rename(columns = rename_map)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 7</summary>
        <pre class="cell-code"><code># Convert to numeric and fix ACS placeholders for unknown data.

placeholders = [
    -666666666, -888888888, -222222222, -333333333,
    -666666666.0, -888888888.0, -222222222.0, -333333333.0,
]

acs = acs.replace(placeholders, np.nan)

for col in acs_variables.keys():
    acs[col] = pd.to_numeric(acs[col], errors = &quot;coerce&quot;)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 8</summary>
        <pre class="cell-code"><code># Remove non-residential tracts.
acs = acs[acs[&quot;total_pop&quot;] &gt;= 50].copy()</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 9</summary>
        <pre class="cell-code"><code># NYC tracts.
nyc_tracts = pygris.tracts(state = &quot;NY&quot;, county = nyc_counties, year = 2022)
nyc_tracts = nyc_tracts.to_crs(&quot;EPSG:2262&quot;)

# Merge to data.
acs = nyc_tracts.merge(acs, on = &quot;GEOID&quot;, how = &quot;inner&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Using FIPS code &#x27;36&#x27; for input &#x27;NY&#x27;
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 10</summary>
        <pre class="cell-code"><code>nyc_tracts.crs</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">&lt;Projected CRS: EPSG:2262&gt;
Name: NAD83 / New York West (ftUS)
Axis Info [cartesian]:
- X[east]: Easting (US survey foot)
- Y[north]: Northing (US survey foot)
Area of Use:
- name: United States (USA) - New York - counties of Allegany; Cattaraugus; Chautauqua; Erie; Genesee; Livingston; Monroe; Niagara; Orleans; Wyoming.
- bounds: (-79.77, 41.99, -77.36, 43.64)
Coordinate Operation:
- name: SPCS83 New York West zone (US survey foot)
- method: Transverse Mercator
Datum: North American Datum 1983
- Ellipsoid: GRS 1980
- Prime Meridian: Greenwich</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 11</summary>
        <pre class="cell-code"><code># Check plot.
acs.plot()</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">&lt;Axes: &gt;</pre>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 12</summary>
        <pre class="cell-code"><code>acs.columns</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">Index([&#x27;STATEFP&#x27;, &#x27;COUNTYFP&#x27;, &#x27;TRACTCE&#x27;, &#x27;GEOID&#x27;, &#x27;NAME_x&#x27;, &#x27;NAMELSAD&#x27;,
       &#x27;MTFCC&#x27;, &#x27;FUNCSTAT&#x27;, &#x27;ALAND&#x27;, &#x27;AWATER&#x27;, &#x27;INTPTLAT&#x27;, &#x27;INTPTLON&#x27;,
       &#x27;geometry&#x27;, &#x27;NAME_y&#x27;, &#x27;total_pop&#x27;, &#x27;median_income&#x27;, &#x27;poverty_all&#x27;,
       &#x27;poverty_count&#x27;, &#x27;no_vehicle_hh&#x27;, &#x27;white&#x27;, &#x27;edu_bachelors&#x27;,
       &#x27;edu_masters&#x27;, &#x27;edu_professional&#x27;, &#x27;edu_doctorate&#x27;, &#x27;edu_total&#x27;,
       &#x27;owner_hh&#x27;, &#x27;renter_hh&#x27;, &#x27;hh_total&#x27;, &#x27;limited_english&#x27;,
       &#x27;limited_english_total&#x27;, &#x27;state&#x27;, &#x27;county&#x27;, &#x27;tract&#x27;],
      dtype=&#x27;object&#x27;)</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 13</summary>
        <pre class="cell-code"><code># Feature engineering.

# Population density.
acs[&quot;pop_density&quot;] = acs[&quot;total_pop&quot;] / acs.geometry.area
acs[&quot;pct_non_white&quot;] = (acs[&quot;total_pop&quot;] - acs[&quot;white&quot;]) / acs[&quot;total_pop&quot;]

# Poverty rate.
acs[&quot;poverty_rate&quot;] = acs[&quot;poverty_count&quot;] / acs[&quot;poverty_all&quot;]
acs[&quot;poverty_rate&quot;] = acs[&quot;poverty_rate&quot;].replace([np.inf, -np.inf], np.nan)

# Centered version.
# Transforms from raw proportion to centered (mean-subtracted) variable.
# Helps with interpretation. Can also be an interaction term with extreme heat to stabilize.
#acs[&quot;poverty_rate_c&quot;] = acs[&quot;poverty_rate&quot;] - acs[&quot;poverty_rate&quot;].mean()

# Education.
acs[&quot;edu_bachelors_plus&quot;] = (
    acs[&quot;edu_bachelors&quot;] +
    acs[&quot;edu_masters&quot;] +
    acs[&quot;edu_professional&quot;] +
    acs[&quot;edu_doctorate&quot;]
)

acs[&quot;pct_bachelors_plus&quot;] = acs[&quot;edu_bachelors_plus&quot;] / acs[&quot;edu_total&quot;]
acs[&quot;pct_bachelors_plus&quot;] = acs[&quot;pct_bachelors_plus&quot;].replace([np.inf, -np.inf], np.nan)

# Housing tenure.
acs[&quot;pct_renters&quot;] = acs[&quot;renter_hh&quot;] / acs[&quot;hh_total&quot;]
acs[&quot;pct_renters&quot;] = acs[&quot;pct_renters&quot;].replace([np.inf, -np.inf], np.nan)

# Limited English proficiency.
acs[&quot;pct_limited_english&quot;] = acs[&quot;limited_english&quot;] / acs[&quot;limited_english_total&quot;]
acs[&quot;pct_limited_english&quot;] = acs[&quot;pct_limited_english&quot;].replace([np.inf, -np.inf], np.nan)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 14</summary>
        <pre class="cell-code"><code>acs.columns</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">Index([&#x27;STATEFP&#x27;, &#x27;COUNTYFP&#x27;, &#x27;TRACTCE&#x27;, &#x27;GEOID&#x27;, &#x27;NAME_x&#x27;, &#x27;NAMELSAD&#x27;,
       &#x27;MTFCC&#x27;, &#x27;FUNCSTAT&#x27;, &#x27;ALAND&#x27;, &#x27;AWATER&#x27;, &#x27;INTPTLAT&#x27;, &#x27;INTPTLON&#x27;,
       &#x27;geometry&#x27;, &#x27;NAME_y&#x27;, &#x27;total_pop&#x27;, &#x27;median_income&#x27;, &#x27;poverty_all&#x27;,
       &#x27;poverty_count&#x27;, &#x27;no_vehicle_hh&#x27;, &#x27;white&#x27;, &#x27;edu_bachelors&#x27;,
       &#x27;edu_masters&#x27;, &#x27;edu_professional&#x27;, &#x27;edu_doctorate&#x27;, &#x27;edu_total&#x27;,
       &#x27;owner_hh&#x27;, &#x27;renter_hh&#x27;, &#x27;hh_total&#x27;, &#x27;limited_english&#x27;,
       &#x27;limited_english_total&#x27;, &#x27;state&#x27;, &#x27;county&#x27;, &#x27;tract&#x27;, &#x27;pop_density&#x27;,
       &#x27;pct_non_white&#x27;, &#x27;poverty_rate&#x27;, &#x27;edu_bachelors_plus&#x27;,
       &#x27;pct_bachelors_plus&#x27;, &#x27;pct_renters&#x27;, &#x27;pct_limited_english&#x27;],
      dtype=&#x27;object&#x27;)</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 15</summary>
        <pre class="cell-code"><code>acs_final = acs.drop([&#x27;STATEFP&#x27;, &#x27;COUNTYFP&#x27;, &#x27;TRACTCE&#x27;, &#x27;NAME_x&#x27;, &#x27;NAMELSAD&#x27;,
                      &#x27;MTFCC&#x27;, &#x27;FUNCSTAT&#x27;, &#x27;ALAND&#x27;, &#x27;AWATER&#x27;, &#x27;INTPTLAT&#x27;, &#x27;INTPTLON&#x27;,
                      &#x27;geometry&#x27;, &#x27;NAME_y&#x27;, &#x27;poverty_all&#x27;, &#x27;poverty_count&#x27;, &#x27;edu_bachelors&#x27;,
                      &#x27;edu_masters&#x27;, &#x27;edu_professional&#x27;, &#x27;edu_doctorate&#x27;, &#x27;edu_total&#x27;,
                      &#x27;owner_hh&#x27;, &#x27;renter_hh&#x27;, &#x27;limited_english&#x27;, &#x27;limited_english_total&#x27;,
                      &#x27;state&#x27;, &#x27;county&#x27;, &#x27;tract&#x27;, &#x27;edu_bachelors_plus&#x27;, &#x27;white&#x27;],
                      axis = 1)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 16</summary>
        <pre class="cell-code"><code>acs_final.columns</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">Index([&#x27;GEOID&#x27;, &#x27;total_pop&#x27;, &#x27;median_income&#x27;, &#x27;no_vehicle_hh&#x27;, &#x27;hh_total&#x27;,
       &#x27;pop_density&#x27;, &#x27;pct_non_white&#x27;, &#x27;poverty_rate&#x27;, &#x27;pct_bachelors_plus&#x27;,
       &#x27;pct_renters&#x27;, &#x27;pct_limited_english&#x27;],
      dtype=&#x27;object&#x27;)</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 17</summary>
        <pre class="cell-code"><code># Impute missing values.
# Only a handful should be missing, fix by tract median or global median.
for col in [
    &quot;pct_bachelors_plus&quot;, &quot;pct_renters&quot;, &quot;pct_limited_english&quot;
]:
    acs_final[col] = acs_final.groupby(&quot;GEOID&quot;)[col].transform(
        lambda x: x.fillna(x.median())
    )
    acs_final[col] = acs_final[col].fillna(acs_final[col].median())</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 18</summary>
        <pre class="cell-code"><code># Save.
acs_final.columns = acs_final.columns.str.upper()

acs_final.to_csv(output_file, index = False)
print(&quot;Saved:&quot;, output_file)

acs_final.head()</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved: data\acs\acs_socioeconomic_tract_2022.csv
</pre>
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GEOID</th>
      <th>TOTAL_POP</th>
      <th>MEDIAN_INCOME</th>
      <th>NO_VEHICLE_HH</th>
      <th>HH_TOTAL</th>
      <th>POP_DENSITY</th>
      <th>PCT_NON_WHITE</th>
      <th>POVERTY_RATE</th>
      <th>PCT_BACHELORS_PLUS</th>
      <th>PCT_RENTERS</th>
      <th>PCT_LIMITED_ENGLISH</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36081045000</td>
      <td>2004</td>
      <td>137109</td>
      <td>35</td>
      <td>761</td>
      <td>0.001056</td>
      <td>0.842315</td>
      <td>0.069860</td>
      <td>0.406198</td>
      <td>0.540079</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36081045400</td>
      <td>4793</td>
      <td>65610</td>
      <td>306</td>
      <td>1696</td>
      <td>0.001920</td>
      <td>0.976633</td>
      <td>0.188608</td>
      <td>0.448410</td>
      <td>0.592571</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36081045500</td>
      <td>13869</td>
      <td>75033</td>
      <td>0</td>
      <td>4482</td>
      <td>0.008659</td>
      <td>0.767395</td>
      <td>0.211639</td>
      <td>0.261328</td>
      <td>1.000000</td>
      <td>0.001110</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36081045600</td>
      <td>1244</td>
      <td>75500</td>
      <td>22</td>
      <td>408</td>
      <td>0.000710</td>
      <td>0.881029</td>
      <td>0.091640</td>
      <td>0.434879</td>
      <td>0.098039</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36081044602</td>
      <td>5210</td>
      <td>44700</td>
      <td>45</td>
      <td>1550</td>
      <td>0.002835</td>
      <td>0.868714</td>
      <td>0.304574</td>
      <td>0.270916</td>
      <td>0.856774</td>
      <td>0.012887</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>

</div></div>

<div class="notebook-section" id="notebook-04_additional_feature">
    <h3 class="notebook-title">4. Additional Features</h3>
    <p class="notebook-description">Computing POI density, subway distance, and other spatial accessibility metrics.</p>
    <div class="notebook-cells">

<div class="cell-markdown"><p><h5>NDVI</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code>## Module
from pathlib import Path
import geopandas as gpd
import rasterio
from rasterio.mask import mask
import numpy as np
import pandas as pd</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code>## File Paths
tracts_path = Path(&quot;data/nyc_tracts_2020/nyc_tracts_2020.shp&quot;)
NDVI_dir = Path(&quot;data/raster/NDVI.tif&quot;)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code># 1. Load NYC census tracts shapefile
tracts = gpd.read_file(tracts_path)

# 2. Open NDVI raster and ensure CRS matches the vector layer
with rasterio.open(NDVI_dir) as src:
    raster_crs = src.crs
    nodata = src.nodata

    # Reproject tracts to match raster CRS if necessary
    if tracts.crs != raster_crs:
        tracts = tracts.to_crs(raster_crs)

    ndvi_means = []

    # 3. Compute zonal mean NDVI for each tract
    for _, row in tracts.iterrows():
        geom = [row.geometry]

        # Mask raster using the tract polygon
        out_image, out_transform = mask(src, geom, crop=True)

        data = out_image[0].astype(&quot;float32&quot;)

        # Replace NoData values with NaN to avoid affecting mean
        if nodata is not None:
            data[data == nodata] = np.nan

        # Compute mean NDVI for this tract
        mean_ndvi = float(np.nanmean(data))
        ndvi_means.append(mean_ndvi)

# 4. Add NDVI results to GeoDataFrame
tracts[&quot;NDVI&quot;] = ndvi_means

tracts.head()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ctlabel</th>
      <th>borocode</th>
      <th>boroname</th>
      <th>ct2020</th>
      <th>boroct2020</th>
      <th>cdeligibil</th>
      <th>ntaname</th>
      <th>nta2020</th>
      <th>cdta2020</th>
      <th>cdtaname</th>
      <th>geoid</th>
      <th>shape_leng</th>
      <th>shape_area</th>
      <th>geometry</th>
      <th>NDVI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>000100</td>
      <td>1000100</td>
      <td>I</td>
      <td>The Battery-Governors Island-Ellis Island-Libe...</td>
      <td>MN0191</td>
      <td>MN01</td>
      <td>MN01 Financial District-Tribeca (CD 1 Equivalent)</td>
      <td>36061000100</td>
      <td>10833.043929</td>
      <td>1.843005e+06</td>
      <td>MULTIPOLYGON (((580787.267 4504805.375, 580819...</td>
      <td>0.024685</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14.01</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>001401</td>
      <td>1001401</td>
      <td>I</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061001401</td>
      <td>5075.332000</td>
      <td>1.006117e+06</td>
      <td>POLYGON ((585444.188 4507772.701, 585514.711 4...</td>
      <td>0.074870</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>001402</td>
      <td>1001402</td>
      <td>E</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061001402</td>
      <td>4459.156019</td>
      <td>1.226206e+06</td>
      <td>POLYGON ((585718.928 4508068.700, 585790.344 4...</td>
      <td>0.046529</td>
    </tr>
    <tr>
      <th>3</th>
      <td>18</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>001800</td>
      <td>1001800</td>
      <td>I</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061001800</td>
      <td>6391.921174</td>
      <td>2.399277e+06</td>
      <td>POLYGON ((585313.281 4508223.568, 585324.698 4...</td>
      <td>0.041547</td>
    </tr>
    <tr>
      <th>4</th>
      <td>22.01</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>002201</td>
      <td>1002201</td>
      <td>E</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061002201</td>
      <td>5779.062607</td>
      <td>1.740174e+06</td>
      <td>POLYGON ((586251.705 4508169.291, 586248.764 4...</td>
      <td>0.063541</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>

<div class="cell-markdown"><p><h4>WCR</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code>## File Paths
water_path = Path(&quot;data/Water shp/NYC_water.shp&quot;)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code>water = gpd.read_file(water_path)

tracts = tracts.to_crs(water.crs)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 6</summary>
        <pre class="cell-code"><code># 1. Compute tract area
tracts[&quot;tract_area&quot;] = tracts.geometry.area

# 2. Intersect tracts with water polygons
#    This will create pieces of water polygons clipped by tract boundaries
water_in_tracts = gpd.overlay(
    tracts[[&quot;geoid&quot;, &quot;geometry&quot;]],
    water[[&quot;geometry&quot;]],
    how=&quot;intersection&quot;
)

# 3. Compute water area inside each tract
water_in_tracts[&quot;water_area&quot;] = water_in_tracts.geometry.area

# 4. Aggregate water area by tract (GEOID)
water_area_by_tract = (
    water_in_tracts
    .groupby(&quot;geoid&quot;)[&quot;water_area&quot;]
    .sum()
)

# 5. Map aggregated water area back to the tracts GeoDataFrame
tracts[&quot;water_area&quot;] = tracts[&quot;geoid&quot;].map(water_area_by_tract).fillna(0)

# 6. Compute Water Coverage Ratio (WCR = water area / tract area)
tracts[&quot;WCR&quot;] = tracts[&quot;water_area&quot;] / tracts[&quot;tract_area&quot;]

# Check the result
tracts[[&quot;geoid&quot;, &quot;NDVI&quot;, &quot;WCR&quot;]].head()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geoid</th>
      <th>NDVI</th>
      <th>WCR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36061000100</td>
      <td>0.024685</td>
      <td>0.017985</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36061001401</td>
      <td>0.074870</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36061001402</td>
      <td>0.046529</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36061001800</td>
      <td>0.041547</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36061002201</td>
      <td>0.063541</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>

<div class="cell-markdown"><p><h4>BD and AH</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 7</summary>
        <pre class="cell-code"><code>building_path = Path(&quot;data/Buildings/geo_export_10da9e2c-833d-4ba4-9fe2-1f999ac16759.shp&quot;)
buildings = gpd.read_file(building_path)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 8</summary>
        <pre class="cell-code"><code>buildings = buildings.to_crs(water.crs)
buildings.crs</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">&lt;Projected CRS: EPSG:32618&gt;
Name: WGS 84 / UTM zone 18N
Axis Info [cartesian]:
- E[east]: Easting (metre)
- N[north]: Northing (metre)
Area of Use:
- name: Between 78Â°W and 72Â°W, northern hemisphere between equator and 84Â°N, onshore and offshore. Bahamas. Canada - Nunavut; Ontario; Quebec. Colombia. Cuba. Ecuador. Greenland. Haiti. Jamaica. Panama. Turks and Caicos Islands. United States (USA). Venezuela.
- bounds: (-78.0, 0.0, -72.0, 84.0)
Coordinate Operation:
- name: UTM zone 18N
- method: Transverse Mercator
Datum: World Geodetic System 1984 ensemble
- Ellipsoid: WGS 84
- Prime Meridian: Greenwich</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 9</summary>
        <pre class="cell-code"><code># 1. Use height_roo as building height (it is in feet), convert to meters
buildings[&quot;bldg_height&quot;] = buildings[&quot;height_roo&quot;] * 0.3048

# 2. Compute building footprint area (in mÂ² because CRS is UTM)
buildings[&quot;bldg_area&quot;] = buildings.geometry.area

# 3. Compute tract area
tracts[&quot;tract_area&quot;] = tracts.geometry.area

# 4. Spatial join â€” assign buildings to tracts
bldg_in_tracts = gpd.sjoin(
    buildings[[&quot;bldg_height&quot;, &quot;bldg_area&quot;, &quot;geometry&quot;]],
    tracts[[&quot;geoid&quot;, &quot;geometry&quot;]],
    how=&quot;inner&quot;,
    predicate=&quot;intersects&quot;
)

# 5. Weighted height sum for AH
bldg_in_tracts[&quot;height_area&quot;] = (
    bldg_in_tracts[&quot;bldg_height&quot;] * bldg_in_tracts[&quot;bldg_area&quot;]
)

# 6. Aggregate by tract
bldg_stats = (
    bldg_in_tracts
    .groupby(&quot;geoid&quot;)
    .agg(
        total_bldg_area=(&quot;bldg_area&quot;, &quot;sum&quot;),
        total_height_area=(&quot;height_area&quot;, &quot;sum&quot;)
    )
)

# 7. Join results back
tracts = tracts.join(bldg_stats, on=&quot;geoid&quot;)

tracts[&quot;total_bldg_area&quot;] = tracts[&quot;total_bldg_area&quot;].fillna(0)

# 8. BD (building density: footprint area ratio)
tracts[&quot;BD&quot;] = tracts[&quot;total_bldg_area&quot;] / tracts[&quot;tract_area&quot;]

# 9. AH (area-weighted building height)
tracts[&quot;AH&quot;] = tracts[&quot;total_height_area&quot;] / tracts[&quot;total_bldg_area&quot;]
tracts.loc[tracts[&quot;total_bldg_area&quot;] == 0, &quot;AH&quot;] = np.nan

# Preview
tracts[[&quot;geoid&quot;, &quot;BD&quot;, &quot;AH&quot;]].head()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geoid</th>
      <th>BD</th>
      <th>AH</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36061000100</td>
      <td>0.242965</td>
      <td>22.344475</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36061001401</td>
      <td>0.170096</td>
      <td>38.401079</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36061001402</td>
      <td>0.391586</td>
      <td>39.186175</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36061001800</td>
      <td>0.407032</td>
      <td>25.738760</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36061002201</td>
      <td>0.282754</td>
      <td>25.412280</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 10</summary>
        <pre class="cell-code"><code>## Save the reusults
# Select only the variables we need (drop geometry implicitly)
tracts_vars = tracts[[&quot;geoid&quot;, &quot;BD&quot;, &quot;AH&quot;, &quot;NDVI&quot;, &quot;WCR&quot;]].copy()

tracts_vars.columns = tracts_vars.columns.str.upper()

# Save to CSV (no index column)
tracts_vars.to_csv(&quot;data/additional_features/nyc_tracts_new_variables.csv&quot;, index=False)

tracts_vars</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geoid</th>
      <th>BD</th>
      <th>AH</th>
      <th>NDVI</th>
      <th>WCR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36061000100</td>
      <td>0.242965</td>
      <td>22.344475</td>
      <td>0.024685</td>
      <td>0.017985</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36061001401</td>
      <td>0.170096</td>
      <td>38.401079</td>
      <td>0.074870</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36061001402</td>
      <td>0.391586</td>
      <td>39.186175</td>
      <td>0.046529</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36061001800</td>
      <td>0.407032</td>
      <td>25.738760</td>
      <td>0.041547</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36061002201</td>
      <td>0.282754</td>
      <td>25.412280</td>
      <td>0.063541</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2320</th>
      <td>36061009903</td>
      <td>0.395851</td>
      <td>111.507287</td>
      <td>0.037452</td>
      <td>0.057454</td>
    </tr>
    <tr>
      <th>2321</th>
      <td>36061011700</td>
      <td>0.412318</td>
      <td>48.834404</td>
      <td>0.018437</td>
      <td>0.024806</td>
    </tr>
    <tr>
      <th>2322</th>
      <td>36061002601</td>
      <td>0.359600</td>
      <td>16.882413</td>
      <td>0.059028</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2323</th>
      <td>36061003200</td>
      <td>0.299328</td>
      <td>20.454839</td>
      <td>0.076770</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2324</th>
      <td>36061000202</td>
      <td>0.194488</td>
      <td>20.841588</td>
      <td>0.048946</td>
      <td>0.001324</td>
    </tr>
  </tbody>
</table>
<p>2325 rows Ã— 5 columns</p>
</div></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 11</summary>
        <pre class="cell-code"><code># Predictor lists.
env_variables = [&quot;TREE_CANOPY_PCT&quot;, &quot;IMPERVIOUS_RATIO&quot;, &quot;WCR&quot;,&quot;NDVI&quot;]
acs_variables = [&quot;PCT_BACHELORS_PLUS&quot;, &quot;PCT_RENTERS&quot;, &quot;PCT_LIMITED_ENGLISH&quot;, &quot;MEDIAN_INCOME&quot;]
urban_variables = [&quot;KNN_SUBWAY&quot;, &quot;POI_DENSITY&quot;, &quot;KNN_PARKS&quot;,&quot;BD&quot;,&quot;AH&quot;]</code></pre>
    </details>
    
</div>

</div></div>

<div class="notebook-section" id="notebook-05_nlcd_calculations">
    <h3 class="notebook-title">5. NLCD Raster Calculations</h3>
    <p class="notebook-description">Zonal statistics for tree canopy and impervious surface from NLCD data.</p>
    <div class="notebook-cells">

<div class="cell-markdown"><p><h5>NLCD RASTERS (SUMMER, 2025)</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code># Modules.
import os
from pathlib import Path
import numpy as np
import rasterio
from rasterio.mask import mask
from rasterio.warp import reproject, Resampling
import geopandas as gpd
from tqdm import tqdm
from rasterstats import zonal_stats</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code># Paths.
nlcd_tree_path = Path(&quot;data/raster/nlcd_raster/nlcd_tree_canopy_2023.tiff&quot;)
nlcd_impervious_path = Path(&quot;data/raster/nyc_impervious_2024.tif&quot;)

tracts_path = Path(&quot;data/nyc_tracts_2020/nyc_tracts_2020.shp&quot;)

output_dir = Path(&quot;data/raster/processed&quot;)
output_dir.mkdir(parents = True, exist_ok = True)

tracts = gpd.read_file(tracts_path).to_crs(32118)

</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code># Zonal statistics for NCLD.
def zonal_mean(rpath, gdf_or_geom):
    &quot;&quot;&quot;Apply CRS zonal mean for tracts or city boundary.&quot;&quot;&quot;
    with rasterio.open(rpath) as src:
        r_crs = src.crs

    if isinstance(gdf_or_geom, (gpd.GeoSeries, gpd.GeoDataFrame)):
        gdf = gdf_or_geom.to_crs(r_crs)
    else:
        gdf = gpd.GeoSeries([gdf_or_geom], crs = 32118).to_crs(r_crs)

    return zonal_stats(gdf, rpath, stats = [&quot;mean&quot;], nodata = np.nan)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code># Print checks for the calculations.
print(&quot;Tree canopy zonal stats:&quot;)
tree = zonal_mean(nlcd_tree_path, tracts)
print(&quot;Impervious zonal stats:&quot;)
impervious = zonal_mean(nlcd_impervious_path, tracts)

tracts[&quot;pct_tree_canopy&quot;] = [t[&quot;mean&quot;] for t in tree]
tracts[&quot;pct_impervious&quot;] = [i[&quot;mean&quot;] for i in impervious]
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Tree canopy zonal stats:
Impervious zonal stats:
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code>tracts.columns = tracts.columns.str.upper()
tracts = tracts.rename(columns = {&quot;GEOMETRY&quot;: &quot;geometry&quot;})

tracts.head()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CTLABEL</th>
      <th>BOROCODE</th>
      <th>BORONAME</th>
      <th>CT2020</th>
      <th>BOROCT2020</th>
      <th>CDELIGIBIL</th>
      <th>NTANAME</th>
      <th>NTA2020</th>
      <th>CDTA2020</th>
      <th>CDTANAME</th>
      <th>GEOID</th>
      <th>SHAPE_LENG</th>
      <th>SHAPE_AREA</th>
      <th>geometry</th>
      <th>PCT_TREE_CANOPY</th>
      <th>PCT_IMPERVIOUS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>000100</td>
      <td>1000100</td>
      <td>I</td>
      <td>The Battery-Governors Island-Ellis Island-Libe...</td>
      <td>MN0191</td>
      <td>MN01</td>
      <td>MN01 Financial District-Tribeca (CD 1 Equivalent)</td>
      <td>36061000100</td>
      <td>10833.043929</td>
      <td>1.843005e+06</td>
      <td>MULTIPOLYGON (((296291.109 58135.715, 296322.4...</td>
      <td>10.126984</td>
      <td>46.973545</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14.01</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>001401</td>
      <td>1001401</td>
      <td>I</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061001401</td>
      <td>5075.332000</td>
      <td>1.006117e+06</td>
      <td>POLYGON ((300982.972 61050.770, 301053.206 610...</td>
      <td>13.314286</td>
      <td>69.590476</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>001402</td>
      <td>1001402</td>
      <td>E</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061001402</td>
      <td>4459.156019</td>
      <td>1.226206e+06</td>
      <td>POLYGON ((301261.149 61343.713, 301332.269 613...</td>
      <td>0.592000</td>
      <td>83.656000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>18</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>001800</td>
      <td>1001800</td>
      <td>I</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061001800</td>
      <td>6391.921174</td>
      <td>2.399277e+06</td>
      <td>POLYGON ((300857.167 61503.238, 300868.535 614...</td>
      <td>3.076305</td>
      <td>81.887550</td>
    </tr>
    <tr>
      <th>4</th>
      <td>22.01</td>
      <td>1</td>
      <td>Manhattan</td>
      <td>002201</td>
      <td>1002201</td>
      <td>E</td>
      <td>Lower East Side</td>
      <td>MN0302</td>
      <td>MN03</td>
      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>
      <td>36061002201</td>
      <td>5779.062607</td>
      <td>1.740174e+06</td>
      <td>POLYGON ((301795.202 61438.261, 301792.173 614...</td>
      <td>6.089888</td>
      <td>78.735955</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 6</summary>
        <pre class="cell-code"><code>tracts.columns</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">Index([&#x27;CTLABEL&#x27;, &#x27;BOROCODE&#x27;, &#x27;BORONAME&#x27;, &#x27;CT2020&#x27;, &#x27;BOROCT2020&#x27;, &#x27;CDELIGIBIL&#x27;,
       &#x27;NTANAME&#x27;, &#x27;NTA2020&#x27;, &#x27;CDTA2020&#x27;, &#x27;CDTANAME&#x27;, &#x27;GEOID&#x27;, &#x27;SHAPE_LENG&#x27;,
       &#x27;SHAPE_AREA&#x27;, &#x27;geometry&#x27;, &#x27;PCT_TREE_CANOPY&#x27;, &#x27;PCT_IMPERVIOUS&#x27;],
      dtype=&#x27;object&#x27;)</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 7</summary>
        <pre class="cell-code"><code>tracts = tracts.drop(columns = [&#x27;CTLABEL&#x27;, &#x27;BOROCODE&#x27;, &#x27;BORONAME&#x27;, &#x27;CT2020&#x27;,
                       &#x27;BOROCT2020&#x27;, &#x27;CDELIGIBIL&#x27;, &#x27;NTANAME&#x27;, &#x27;NTA2020&#x27;,
                       &#x27;CDTA2020&#x27;, &#x27;CDTANAME&#x27;, &#x27;SHAPE_LENG&#x27;, &#x27;SHAPE_AREA&#x27;])</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 8</summary>
        <pre class="cell-code"><code>tracts.columns</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">Index([&#x27;GEOID&#x27;, &#x27;geometry&#x27;, &#x27;PCT_TREE_CANOPY&#x27;, &#x27;PCT_IMPERVIOUS&#x27;], dtype=&#x27;object&#x27;)</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 9</summary>
        <pre class="cell-code"><code># Save as geojson.
geojson_out = output_dir.parent / &quot;nlcd_calc_tracts.geojson&quot;
geojson_out.parent.mkdir(parents = True, exist_ok = True)
tracts.to_file(geojson_out)
print(&quot;Saved:&quot;, geojson_out)

# Save as csv.
csv_out = output_dir.parent / &quot;nlcd_calc_tracts.csv&quot;
tracts.drop(columns = [&quot;geometry&quot;]).to_csv(csv_out, index = False)
print(&quot;Saved CSV:&quot;, csv_out)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved: data\raster\nlcd_calc_tracts.geojson
Saved CSV: data\raster\nlcd_calc_tracts.csv
</pre>
</div>
</div>

</div></div>

<div class="notebook-section" id="notebook-06_data_merge_cleaning">
    <h3 class="notebook-title">6. Data Merging &amp; Cleaning</h3>
    <p class="notebook-description">Combining all datasets and preparing final analysis-ready table.</p>
    <div class="notebook-cells">


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code>import pandas as pd
import numpy as np
from pathlib import Path
import geopandas as gpd</code></pre>
    </details>
    
</div>

<div class="cell-markdown"><p><h4>Define heat weeks</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code>import pandas as pd

# Load the dataset
df = pd.read_csv(&quot;data/heat/JFK_2025_JJA_extreme_heat_90.csv&quot;)

# Convert DATE column to datetime
df[&#x27;DATE&#x27;] = pd.to_datetime(df[&#x27;DATE&#x27;])

# Define the start of week0 (2025-06-01 is Sunday)
week0_start = pd.Timestamp(&quot;2025-06-01&quot;)

# Compute week index (Sundayâ€“Saturday as one week)
df[&#x27;week&#x27;] = ((df[&#x27;DATE&#x27;] - week0_start).dt.days // 7).astype(int)

# Keep only week0 to week11 (drop last incomplete week12)
df = df[df[&#x27;week&#x27;] &lt;= 11]

# Create heat day flag: 1 if EXTREME_HEAT == &quot;yes&quot;
df[&#x27;heat_flag&#x27;] = (df[&#x27;EXTREME_HEAT&#x27;] == &#x27;yes&#x27;).astype(int)

# Aggregate heat days by week
weekly = (
    df.groupby(&#x27;week&#x27;)[&#x27;heat_flag&#x27;]
    .sum()
    .reset_index()
    .rename(columns={&#x27;heat_flag&#x27;: &#x27;heat_days&#x27;})
)

# Determine heat weeks (&gt;= 2 heat days)
weekly[&#x27;is_heat_week&#x27;] = (weekly[&#x27;heat_days&#x27;] &gt;= 2).astype(int)

weekly
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>week</th>
      <th>heat_days</th>
      <th>is_heat_week</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>7</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>10</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>11</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>

<div class="cell-markdown"><p><h4>Agreggate weekly avergae 311 calls for heat/non-heat weeks for each tracts</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code>import pandas as pd
from pathlib import Path


# 1. Load data

# 311 daily calls (panel) â€“ use the file you just saved
calls_path    = Path(&quot;data/nyc_311/nyc_311_tract_day_2025.csv&quot;)
calls = pd.read_csv(calls_path, parse_dates=[&quot;DATE&quot;])

# 2. Assign each day to a week index (0â€“11), Sundayâ€“Saturday
start_date = pd.Timestamp(&quot;2025-06-01&quot;)  # week 0 starts on this Sunday

# Compute integer week index, Sundayâ€“Saturday = one week
calls[&quot;week&quot;] = ((calls[&quot;DATE&quot;] - start_date).dt.days // 7)

# Keep only full weeks 0â€“11 (drop incomplete weeks outside this range)
calls = calls[(calls[&quot;week&quot;] &gt;= 0) &amp; (calls[&quot;week&quot;] &lt;= 11)].copy()

# 3. Aggregate to weekly calls per GEOID

weekly_calls = (
    calls
    .groupby([&quot;GEOID&quot;, &quot;week&quot;], as_index=False)
    .agg(weekly_qol_calls=(&quot;QOL_CALLS&quot;, &quot;sum&quot;))  # total QOL_CALLS in that tract-week
)

# 4. Identify heat weeks and normal weeks from `weekly`

heat_weeks = weekly.loc[weekly[&quot;is_heat_week&quot;] == 1, &quot;week&quot;].tolist()
normal_weeks = weekly.loc[weekly[&quot;is_heat_week&quot;] == 0, &quot;week&quot;].tolist()

# 5. For each GEOID, compute average weekly calls in heat weeks and in normal weeks

# Average QOL_CALLS over heat weeks (only weeks in `heat_weeks`)
heat_avg = (
    weekly_calls[weekly_calls[&quot;week&quot;].isin(heat_weeks)]
    .groupby(&quot;GEOID&quot;, as_index=False)
    .agg(heatweek_avg_qol_calls=(&quot;weekly_qol_calls&quot;, &quot;mean&quot;))
)

# Average QOL_CALLS over normal weeks
normal_avg = (
    weekly_calls[weekly_calls[&quot;week&quot;].isin(normal_weeks)]
    .groupby(&quot;GEOID&quot;, as_index=False)
    .agg(normalweek_avg_qol_calls=(&quot;weekly_qol_calls&quot;, &quot;mean&quot;))
)

# 6. Merge to final df: one row per GEOID

final_df = heat_avg.merge(normal_avg, on=&quot;GEOID&quot;, how=&quot;outer&quot;)

# Drop rows that contain NaN in either heatweek or normalweek averages
heatweek311 = final_df.dropna(subset=[&quot;heatweek_avg_qol_calls&quot;,
                                   &quot;normalweek_avg_qol_calls&quot;])

# 7. Save to CSV
out_path = Path(&quot;data/heat_311/heat_week_311_calls.csv&quot;)
heatweek311.to_csv(out_path, index=False)
print(&quot;Saved:&quot;, out_path)
heatweek311.head()
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved: data\heat_311\heat_week_311_calls.csv
</pre>
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GEOID</th>
      <th>heatweek_avg_qol_calls</th>
      <th>normalweek_avg_qol_calls</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36005000100</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36005000200</td>
      <td>18.2</td>
      <td>15.857143</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36005000400</td>
      <td>8.6</td>
      <td>9.285714</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36005001600</td>
      <td>6.8</td>
      <td>7.142857</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36005001901</td>
      <td>14.2</td>
      <td>5.714286</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code>heatweek311</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GEOID</th>
      <th>heatweek_avg_qol_calls</th>
      <th>normalweek_avg_qol_calls</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36005000100</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36005000200</td>
      <td>18.2</td>
      <td>15.857143</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36005000400</td>
      <td>8.6</td>
      <td>9.285714</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36005001600</td>
      <td>6.8</td>
      <td>7.142857</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36005001901</td>
      <td>14.2</td>
      <td>5.714286</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2313</th>
      <td>36085030301</td>
      <td>7.8</td>
      <td>7.285714</td>
    </tr>
    <tr>
      <th>2314</th>
      <td>36085030302</td>
      <td>7.2</td>
      <td>9.000000</td>
    </tr>
    <tr>
      <th>2315</th>
      <td>36085031901</td>
      <td>1.0</td>
      <td>1.428571</td>
    </tr>
    <tr>
      <th>2316</th>
      <td>36085031902</td>
      <td>1.8</td>
      <td>4.142857</td>
    </tr>
    <tr>
      <th>2317</th>
      <td>36085032300</td>
      <td>1.6</td>
      <td>1.428571</td>
    </tr>
  </tbody>
</table>
<p>2316 rows Ã— 3 columns</p>
</div></div>
</div>
</div>

<div class="cell-markdown"><p><h4>Calcuate QoF density: calls/population</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code>acs_path = Path(&quot;data/acs/acs_socioeconomic_tract_2022.csv&quot;)
acs = pd.read_csv(acs_path, dtype = {&quot;GEOID&quot;: str})
heatweek311[&quot;GEOID&quot;] = heatweek311[&quot;GEOID&quot;].astype(str)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">C:\Users\DZM\AppData\Local\Temp\ipykernel_22816\942666503.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  heatweek311[&quot;GEOID&quot;] = heatweek311[&quot;GEOID&quot;].astype(str)
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 6</summary>
        <pre class="cell-code"><code>acs_use = acs[[&quot;GEOID&quot;, &quot;TOTAL_POP&quot;]].copy()

# Left join heatweek311 df with ACS
Targets = heatweek311.merge(acs_use, on=&quot;GEOID&quot;, how=&quot;left&quot;)

# Drop rows where TOTAL_POP is NaN
Targets = Targets.dropna(subset=[&quot;TOTAL_POP&quot;])

# Calculate density
Targets[&quot;heatweek_calls_per_1k&quot;] = (
    Targets[&quot;heatweek_avg_qol_calls&quot;] / Targets[&quot;TOTAL_POP&quot;] * 1000
)

Targets[&quot;normalweek_calls_per_1k&quot;] = (
    Targets[&quot;normalweek_avg_qol_calls&quot;] / Targets[&quot;TOTAL_POP&quot;] * 1000
)

out_path = Path(&quot;data/model/target_variables.csv&quot;)
Targets.to_csv(out_path, index=False)
print(&quot;Saved:&quot;, out_path)
Targets</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved: data\model\target_variables.csv
</pre>
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GEOID</th>
      <th>heatweek_avg_qol_calls</th>
      <th>normalweek_avg_qol_calls</th>
      <th>TOTAL_POP</th>
      <th>heatweek_calls_per_1k</th>
      <th>normalweek_calls_per_1k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36005000100</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>4446.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36005000200</td>
      <td>18.2</td>
      <td>15.857143</td>
      <td>4870.0</td>
      <td>3.737166</td>
      <td>3.256087</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36005000400</td>
      <td>8.6</td>
      <td>9.285714</td>
      <td>6257.0</td>
      <td>1.374461</td>
      <td>1.484052</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36005001600</td>
      <td>6.8</td>
      <td>7.142857</td>
      <td>6177.0</td>
      <td>1.100858</td>
      <td>1.156363</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36005001901</td>
      <td>14.2</td>
      <td>5.714286</td>
      <td>2181.0</td>
      <td>6.510775</td>
      <td>2.620030</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2311</th>
      <td>36085030301</td>
      <td>7.8</td>
      <td>7.285714</td>
      <td>5915.0</td>
      <td>1.318681</td>
      <td>1.231735</td>
    </tr>
    <tr>
      <th>2312</th>
      <td>36085030302</td>
      <td>7.2</td>
      <td>9.000000</td>
      <td>6374.0</td>
      <td>1.129589</td>
      <td>1.411986</td>
    </tr>
    <tr>
      <th>2313</th>
      <td>36085031901</td>
      <td>1.0</td>
      <td>1.428571</td>
      <td>3674.0</td>
      <td>0.272183</td>
      <td>0.388833</td>
    </tr>
    <tr>
      <th>2314</th>
      <td>36085031902</td>
      <td>1.8</td>
      <td>4.142857</td>
      <td>5053.0</td>
      <td>0.356224</td>
      <td>0.819881</td>
    </tr>
    <tr>
      <th>2315</th>
      <td>36085032300</td>
      <td>1.6</td>
      <td>1.428571</td>
      <td>1133.0</td>
      <td>1.412180</td>
      <td>1.260875</td>
    </tr>
  </tbody>
</table>
<p>2229 rows Ã— 6 columns</p>
</div></div>
</div>
</div>

<div class="cell-markdown"><p><h4>Visulization / Choropleth Map</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 7</summary>
        <pre class="cell-code"><code>import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import BoundaryNorm
import mapclassify as mc
from pathlib import Path

tracts_path = Path(&quot;data/nyc_tracts_2020/nyc_tracts_2020.shp&quot;)
tracts = gpd.read_file(tracts_path)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 8</summary>
        <pre class="cell-code"><code>## Histogram
import pandas as pd
import matplotlib.pyplot as plt

# Load your dataframe
df = pd.read_csv(&quot;data/model/target_variables.csv&quot;)

# Select the two target columns
cols = [&quot;heatweek_calls_per_1k&quot;, &quot;normalweek_calls_per_1k&quot;]

# Plot histograms
plt.figure(figsize=(12, 5))

# Histogram for heatweek_calls_per_1k
plt.subplot(1, 2, 1)
plt.hist(df[&quot;heatweek_calls_per_1k&quot;], bins=200)
plt.xlabel(&quot;Calls per 1k Population&quot;)
plt.ylabel(&quot;Frequency&quot;)

# Histogram for normalweek_calls_per_1k
plt.subplot(1, 2, 2)
plt.hist(df[&quot;normalweek_calls_per_1k&quot;], bins=200)
plt.title(&quot;Histogram of Normal Week Calls per 1k&quot;)
plt.xlabel(&quot;Calls per 1k Population&quot;)
plt.ylabel(&quot;Frequency&quot;)

plt.tight_layout()
plt.show()
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 9</summary>
        <pre class="cell-code"><code># Ensure GEOID is stored as a string in both dataframes
if &quot;GEOID&quot; in tracts.columns:
    tracts[&quot;GEOID&quot;] = tracts[&quot;GEOID&quot;].astype(str)
elif &quot;geoid&quot; in tracts.columns:
    tracts[&quot;GEOID&quot;] = tracts[&quot;geoid&quot;].astype(str)

Targets[&quot;GEOID&quot;] = Targets[&quot;GEOID&quot;].astype(str)

# 2. Merge 311 indicators onto the tract boundaries

mapdf = tracts.merge(Targets, on=&quot;GEOID&quot;, how=&quot;inner&quot;)

# 3. Summary statistics for both variables

h = mapdf[&quot;heatweek_calls_per_1k&quot;]
n = mapdf[&quot;normalweek_calls_per_1k&quot;]

def summary_text(s):
    return (
        f&quot;count:  {int(s.count())}\n&quot;
        f&quot;mean:   {s.mean():.2f}\n&quot;
        f&quot;median: {s.median():.2f}\n&quot;
        f&quot;std:    {s.std():.2f}\n&quot;
        f&quot;min:    {s.min():.2f}\n&quot;
        f&quot;max:    {s.max():.2f}&quot;
    )

h_text = summary_text(h)
n_text = summary_text(n)

# 3. Manual class breaks, shared by both maps
#    (Tune these numbers based on your histogram if you like)
# ------------------------------------------------------------
combined = np.concatenate([h.values, n.values])
combined = combined[~np.isnan(combined)]

# Base breaks focusing on the main mass (0â€“8), last bin catches extremes
base_bins = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])

max_val = combined.max()
if max_val &gt; base_bins[-1]:
    bins = np.append(base_bins, max_val)
else:
    bins = base_bins

# boundaries are the full class edges for BoundaryNorm
boundaries = bins

cmap = plt.cm.OrRd
norm = BoundaryNorm(boundaries, ncolors=cmap.N)

# ------------------------------------------------------------
# 4. Plot two maps with shared manual classes and one colorbar
# ------------------------------------------------------------
fig, axes = plt.subplots(1, 2, figsize=(16, 7), constrained_layout=True)

# --- Extreme Heat Week (left) ---
mapdf.plot(
    column=&quot;heatweek_calls_per_1k&quot;,
    cmap=cmap,
    norm=norm,
    scheme=&quot;user_defined&quot;,
    classification_kwds={&quot;bins&quot;: bins[1:]},  # upper bounds for each class
    linewidth=0,
    ax=axes[0],
    legend=False
)
axes[0].set_title(&quot;Extreme Heat Week&quot;)
axes[0].axis(&quot;off&quot;)

axes[0].text(
    0.02, 0.98, h_text,
    transform=axes[0].transAxes,
    fontsize=9,
    va=&quot;top&quot;, ha=&quot;left&quot;,
    bbox=dict(facecolor=&quot;white&quot;, edgecolor=&quot;black&quot;, alpha=0.8)
)

# --- Normal Heat Week (right) ---
mapdf.plot(
    column=&quot;normalweek_calls_per_1k&quot;,
    cmap=cmap,
    norm=norm,
    scheme=&quot;user_defined&quot;,
    classification_kwds={&quot;bins&quot;: bins[1:]},
    linewidth=0,
    ax=axes[1],
    legend=False
)
axes[1].set_title(&quot;Normal Heat Week&quot;)
axes[1].axis(&quot;off&quot;)

axes[1].text(
    0.02, 0.98, n_text,
    transform=axes[1].transAxes,
    fontsize=9,
    va=&quot;top&quot;, ha=&quot;left&quot;,
    bbox=dict(facecolor=&quot;white&quot;, edgecolor=&quot;black&quot;, alpha=0.8)
)

# ------------------------------------------------------------
# 5. Shared discrete colorbar with class boundaries
# ------------------------------------------------------------
sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)
sm.set_array([])

cbar = fig.colorbar(
    sm,
    ax=axes.ravel().tolist(),
    fraction=0.03,
    pad=0.02,
    ticks=bins
)
# Round tick labels a bit for readability
cbar.set_ticklabels([f&quot;{b:.1f}&quot; for b in bins])
cbar.set_label(&quot;QoL calls per 1,000 residents per week&quot;)

plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h4>Final Dataframe for Model</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 10</summary>
        <pre class="cell-code"><code>acs_path      = Path(&quot;data/acs/acs_socioeconomic_tract_2022.csv&quot;)
nlcd_path     = Path(&quot;data/raster/nlcd_calc_tracts.csv&quot;)
addfeat_path  = Path(&quot;data/additional_features/nyc_tracts_new_variables.csv&quot;)
targets_path    = Path(&quot;data/model/target_variables.csv&quot;)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 11</summary>
        <pre class="cell-code"><code>acs = pd.read_csv(acs_path, dtype = {&quot;GEOID&quot;: str})
nlcd = pd.read_csv(nlcd_path, dtype = {&quot;GEOID&quot;: str})
addfeat = pd.read_csv(addfeat_path, dtype = {&quot;GEOID&quot;: str})
targets = pd.read_csv(targets_path, dtype = {&quot;GEOID&quot;: str})</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 12</summary>
        <pre class="cell-code"><code># 1. Left join all feature tables to targets on GEOID
merged = (
    targets
    .merge(acs,     on=&quot;GEOID&quot;, how=&quot;left&quot;)
    .merge(nlcd,    on=&quot;GEOID&quot;, how=&quot;left&quot;)
    .merge(addfeat, on=&quot;GEOID&quot;, how=&quot;left&quot;)
)

# 2. Drop rows with ANY missing values after merging
model_raw = merged.dropna()

# 3. Select Columns
model_raw
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-note">ðŸ“‹ <em>[Large table - see notebook for full output]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 13</summary>
        <pre class="cell-code"><code># Define the columns you want to keep
wanted_cols = [
    &quot;GEOID&quot;,
    &quot;TOTAL_POP_x&quot;,
    &quot;heatweek_avg_qol_calls&quot;,
    &quot;normalweek_avg_qol_calls&quot;,
    &quot;heatweek_calls_per_1k&quot;,
    &quot;normalweek_calls_per_1k&quot;,
    
    # --- ACS variables ---
    &quot;PCT_BACHELORS_PLUS&quot;,
    &quot;PCT_RENTERS&quot;,
    &quot;PCT_LIMITED_ENGLISH&quot;,
    &quot;MEDIAN_INCOME&quot;,
    &quot;POVERTY_RATE&quot;,
    &quot;PCT_NON_WHITE&quot;,

    # --- NLCD /  env variables ---
    &quot;PCT_TREE_CANOPY&quot;,
    &quot;PCT_IMPERVIOUS&quot;,
    &quot;WCR&quot;,
    &quot;NDVI&quot;,

    # --- Additional features ---
    &quot;BD&quot;,   # Building density.
    &quot;AH&quot;
]

# Select only those columns
model_final = model_raw.loc[:, wanted_cols].copy()

model_final.head()
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GEOID</th>
      <th>TOTAL_POP_x</th>
      <th>heatweek_avg_qol_calls</th>
      <th>normalweek_avg_qol_calls</th>
      <th>heatweek_calls_per_1k</th>
      <th>normalweek_calls_per_1k</th>
      <th>PCT_BACHELORS_PLUS</th>
      <th>PCT_RENTERS</th>
      <th>PCT_LIMITED_ENGLISH</th>
      <th>MEDIAN_INCOME</th>
      <th>POVERTY_RATE</th>
      <th>PCT_NON_WHITE</th>
      <th>PCT_TREE_CANOPY</th>
      <th>PCT_IMPERVIOUS</th>
      <th>WCR</th>
      <th>NDVI</th>
      <th>BD</th>
      <th>AH</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>36005000200</td>
      <td>4870.0</td>
      <td>18.2</td>
      <td>15.857143</td>
      <td>3.737166</td>
      <td>3.256087</td>
      <td>0.323751</td>
      <td>0.397895</td>
      <td>0.019587</td>
      <td>115064</td>
      <td>0.141273</td>
      <td>0.845996</td>
      <td>11.903162</td>
      <td>66.351779</td>
      <td>0.011789</td>
      <td>0.073005</td>
      <td>0.211474</td>
      <td>6.968560</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36005000400</td>
      <td>6257.0</td>
      <td>8.6</td>
      <td>9.285714</td>
      <td>1.374461</td>
      <td>1.484052</td>
      <td>0.337057</td>
      <td>0.389779</td>
      <td>0.006332</td>
      <td>100553</td>
      <td>0.060412</td>
      <td>0.873741</td>
      <td>20.981900</td>
      <td>53.535068</td>
      <td>0.031757</td>
      <td>0.100404</td>
      <td>0.144159</td>
      <td>8.609242</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36005001600</td>
      <td>6177.0</td>
      <td>6.8</td>
      <td>7.142857</td>
      <td>1.100858</td>
      <td>1.156363</td>
      <td>0.194351</td>
      <td>0.794104</td>
      <td>0.015487</td>
      <td>41362</td>
      <td>0.149807</td>
      <td>0.910798</td>
      <td>9.801484</td>
      <td>70.717996</td>
      <td>0.000000</td>
      <td>0.106988</td>
      <td>0.171576</td>
      <td>13.881170</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36005001901</td>
      <td>2181.0</td>
      <td>14.2</td>
      <td>5.714286</td>
      <td>6.510775</td>
      <td>2.620030</td>
      <td>0.304911</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>49500</td>
      <td>0.286042</td>
      <td>0.786337</td>
      <td>1.806034</td>
      <td>81.900862</td>
      <td>0.010903</td>
      <td>0.038412</td>
      <td>0.213645</td>
      <td>28.281232</td>
    </tr>
    <tr>
      <th>5</th>
      <td>36005001902</td>
      <td>1883.0</td>
      <td>2.0</td>
      <td>4.428571</td>
      <td>1.062135</td>
      <td>2.351870</td>
      <td>0.109692</td>
      <td>0.848291</td>
      <td>0.005114</td>
      <td>67375</td>
      <td>0.323043</td>
      <td>0.865109</td>
      <td>1.802657</td>
      <td>83.533207</td>
      <td>0.000000</td>
      <td>0.026393</td>
      <td>0.296425</td>
      <td>10.708307</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>

<div class="cell-markdown"><p><h4>Add Spatial Features</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 14</summary>
        <pre class="cell-code"><code># Import utility libraries.
from tqdm import tqdm
import warnings

# Suppress warnings for cleaner output.
warnings.filterwarnings(&quot;ignore&quot;)

import osmnx as ox
import networkx as nx
from shapely.geometry import Point
import libpysal as ps
from sklearn.neighbors import BallTree</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 15</summary>
        <pre class="cell-code"><code>tracts_path = Path(&quot;data/nyc_tracts_2020/nyc_tracts_2020.shp&quot;)
tracts = gpd.read_file(tracts_path)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 16</summary>
        <pre class="cell-code"><code># Download Points of Interest (POIs) from OpenStreetMap for New York City.
# POIs include amenities like restaurants, shops, parks, and other urban features.
print(&quot;\nDownloading Points of Interest from OpenStreetMap...&quot;)

# Define the tags for POI features we want to download.
tags = {
    &quot;amenity&quot;: [
        &quot;library&quot;,
        &quot;community_centre&quot;, 
        &quot;social_facility&quot;,
        &quot;bus_station&quot;,
        &quot;bar&quot;,
        &quot;restaurant&quot;,
        &quot;fast_food&quot;,
        &quot;toilets&quot;,
        &quot;hospital&quot;,
        &quot;clinic&quot;,
        &quot;pharmacy&quot;
    ],
    &quot;shop&quot;: [
        &quot;convenience&quot;,
        &quot;supermarket&quot;,
        &quot;alcohol&quot;,
        &quot;deli&quot;
    ],
    &quot;leisure&quot;: [&quot;park&quot;],
    &quot;public_transport&quot;: [&quot;station&quot;]
}

# Download POIs as points for New York City.
pois = ox.features_from_place(
    &quot;New York City, New York, USA&quot;, 
    tags=tags
)

# Filter to only include point geometries for easier density calculations.
pois = pois[pois.geometry.type == &quot;Point&quot;]

# Project POIs to match the coordinate reference system of our tracts.
pois = pois.to_crs(&quot;EPSG:32118&quot;)

print(f&quot;Downloaded {len(pois)} POI points.&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">
Downloading Points of Interest from OpenStreetMap...
Downloaded 21309 POI points.
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 17</summary>
        <pre class="cell-code"><code>tracts = tracts.to_crs(&quot;EPSG:32118&quot;)

# Calculate POI density within a buffer around each tract centroid.
# This provides a measure of urban amenity accessibility for each tract.
print(&quot;\nCalculating POI density within 500m buffer of each tract centroid...&quot;)

# create centroids
tracts[&quot;centroid&quot;] = tracts.geometry.centroid

# Define the buffer distance 
buffer_distance = 500

# Initialize an empty list to store POI counts.
poi_counts = []

# Iterate through each tract to count POIs within the buffer.
for idx, row in tqdm(tracts.iterrows(), total=len(tracts), desc=&quot;Calculating POI density&quot;):
    # Create a circular buffer around the tract centroid.
    buffer = row[&quot;centroid&quot;].buffer(buffer_distance)
    
    # Count the number of POIs that fall within this buffer.
    poi_count = pois[pois.within(buffer)].shape[0]
    
    poi_counts.append(poi_count)

# Add the POI density counts to the tracts GeoDataFrame.
tracts[&quot;POI_500M_DENSITY&quot;] = poi_counts

print(f&quot;POI density calculation complete. Mean POI count: {tracts[&#x27;POI_500M_DENSITY&#x27;].mean():.2f} per tract.&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">
Calculating POI density within 500m buffer of each tract centroid...
</pre>
<pre class="output-stream">Calculating POI density: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2325/2325 [00:13&lt;00:00, 169.03it/s]</pre>
<pre class="output-stream">POI density calculation complete. Mean POI count: 37.14 per tract.
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 18</summary>
        <pre class="cell-code"><code># Download subway station locations from OpenStreetMap.
# Subway access is an important urban amenity that can affect quality of life.
print(&quot;\nDownloading subway station locations...&quot;)

# Define the tags to identify subway stations in OSM data.
subway_tags = {&quot;railway&quot;: &quot;station&quot;, &quot;station&quot;: &quot;subway&quot;}

# Download subway stations as points.
subway_stations = ox.features_from_place(
    &quot;New York City, New York, USA&quot;, 
    tags=subway_tags
)

# Filter to only include point geometries.
subway_stations = subway_stations[subway_stations.geometry.type == &quot;Point&quot;]

# Project to match our tract CRS.
subway_stations = subway_stations.to_crs(&quot;EPSG:32118&quot;)

print(f&quot;Downloaded {len(subway_stations)} subway station locations.&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">
Downloading subway station locations...
Downloaded 550 subway station locations.
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 19</summary>
        <pre class="cell-code"><code># Calculate the mean distance to the K nearest subway stations for each tract.
# This provides a measure of transit accessibility.
print(&quot;\nCalculating K-Nearest Neighbor distances to subway stations...&quot;)

# Define the number of nearest neighbors to consider.
k = 5

# Extract coordinates from subway stations.
subway_coords = np.array([[point.x, point.y] for point in subway_stations.geometry])

# Extract coordinates from tract centroids.
tract_coords = np.column_stack((
    tracts[&quot;centroid&quot;].x.values,
    tracts[&quot;centroid&quot;].y.values
))

# Build a BallTree for efficient nearest neighbor queries.
# BallTree is optimized for spatial queries in multiple dimensions.
tree = BallTree(subway_coords, metric=&quot;euclidean&quot;)

# Query the tree to find distances to the k nearest subway stations.
distances, indices = tree.query(tract_coords, k=k)

# Calculate the mean distance to the k nearest stations for each tract.
tracts[&quot;KNN_SUBWAY_dist_mean&quot;] = distances.mean(axis=1)

print(f&quot;KNN distance calculation complete. Mean distance to {k} nearest subway stations: {tracts[&#x27;KNN_SUBWAY_dist_mean&#x27;].mean():.2f} feet.&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">
Calculating K-Nearest Neighbor distances to subway stations...
KNN distance calculation complete. Mean distance to 5 nearest subway stations: 1278.57 feet.
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 20</summary>
        <pre class="cell-code"><code># Select only GEOID + new columns from tracts
tracts = tracts.rename(columns={&quot;geoid&quot;: &quot;GEOID&quot;})

tract_features = tracts[[&quot;GEOID&quot;, &quot;POI_500M_DENSITY&quot;, &quot;KNN_SUBWAY_dist_mean&quot;]].copy()

# Merge into modelfine (left join)
model_final = model_final.merge(tract_features, on=&quot;GEOID&quot;, how=&quot;left&quot;)

# Drop rows missing any of the new variables
model_final = model_final.dropna(subset=[&quot;POI_500M_DENSITY&quot;, &quot;KNN_SUBWAY_dist_mean&quot;])

model_final.head()
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GEOID</th>
      <th>TOTAL_POP_x</th>
      <th>heatweek_avg_qol_calls</th>
      <th>normalweek_avg_qol_calls</th>
      <th>heatweek_calls_per_1k</th>
      <th>normalweek_calls_per_1k</th>
      <th>PCT_BACHELORS_PLUS</th>
      <th>PCT_RENTERS</th>
      <th>PCT_LIMITED_ENGLISH</th>
      <th>MEDIAN_INCOME</th>
      <th>POVERTY_RATE</th>
      <th>PCT_NON_WHITE</th>
      <th>PCT_TREE_CANOPY</th>
      <th>PCT_IMPERVIOUS</th>
      <th>WCR</th>
      <th>NDVI</th>
      <th>BD</th>
      <th>AH</th>
      <th>POI_500M_DENSITY</th>
      <th>KNN_SUBWAY_dist_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36005000200</td>
      <td>4870.0</td>
      <td>18.2</td>
      <td>15.857143</td>
      <td>3.737166</td>
      <td>3.256087</td>
      <td>0.323751</td>
      <td>0.397895</td>
      <td>0.019587</td>
      <td>115064</td>
      <td>0.141273</td>
      <td>0.845996</td>
      <td>11.903162</td>
      <td>66.351779</td>
      <td>0.011789</td>
      <td>0.073005</td>
      <td>0.211474</td>
      <td>6.968560</td>
      <td>0</td>
      <td>2536.704079</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36005000400</td>
      <td>6257.0</td>
      <td>8.6</td>
      <td>9.285714</td>
      <td>1.374461</td>
      <td>1.484052</td>
      <td>0.337057</td>
      <td>0.389779</td>
      <td>0.006332</td>
      <td>100553</td>
      <td>0.060412</td>
      <td>0.873741</td>
      <td>20.981900</td>
      <td>53.535068</td>
      <td>0.031757</td>
      <td>0.100404</td>
      <td>0.144159</td>
      <td>8.609242</td>
      <td>1</td>
      <td>2729.080135</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36005001600</td>
      <td>6177.0</td>
      <td>6.8</td>
      <td>7.142857</td>
      <td>1.100858</td>
      <td>1.156363</td>
      <td>0.194351</td>
      <td>0.794104</td>
      <td>0.015487</td>
      <td>41362</td>
      <td>0.149807</td>
      <td>0.910798</td>
      <td>9.801484</td>
      <td>70.717996</td>
      <td>0.000000</td>
      <td>0.106988</td>
      <td>0.171576</td>
      <td>13.881170</td>
      <td>3</td>
      <td>1789.242256</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36005001901</td>
      <td>2181.0</td>
      <td>14.2</td>
      <td>5.714286</td>
      <td>6.510775</td>
      <td>2.620030</td>
      <td>0.304911</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>49500</td>
      <td>0.286042</td>
      <td>0.786337</td>
      <td>1.806034</td>
      <td>81.900862</td>
      <td>0.010903</td>
      <td>0.038412</td>
      <td>0.213645</td>
      <td>28.281232</td>
      <td>19</td>
      <td>735.633299</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36005001902</td>
      <td>1883.0</td>
      <td>2.0</td>
      <td>4.428571</td>
      <td>1.062135</td>
      <td>2.351870</td>
      <td>0.109692</td>
      <td>0.848291</td>
      <td>0.005114</td>
      <td>67375</td>
      <td>0.323043</td>
      <td>0.865109</td>
      <td>1.802657</td>
      <td>83.533207</td>
      <td>0.000000</td>
      <td>0.026393</td>
      <td>0.296425</td>
      <td>10.708307</td>
      <td>9</td>
      <td>824.318546</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 21</summary>
        <pre class="cell-code"><code>out_path = Path(&quot;data/model/Final_Data_Model.csv&quot;)
model_final.to_csv(out_path, index=False)
print(&quot;Saved:&quot;, out_path)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Saved: data\model\Final_Data_Model.csv
</pre>
</div>
</div>

</div></div>

<div class="notebook-section" id="notebook-eda">
    <h3 class="notebook-title">7. Exploratory Data Analysis</h3>
    <p class="notebook-description">Visualizations and summary statistics of the merged dataset.</p>
    <div class="notebook-cells">

<div class="cell-markdown"><p><h4>Hot City, Heated Calls: EDA</h4>
<h4>Understanding Extreme Heat and Quality of Life Using NYC's 311 and SHAP</h4></p><p><strong>Goal:</strong> Estimate how heat exposure changes urban livabilityâ€”proxied by the rate of quality-of-life (QoL)-related 311 complaints per capitaâ€”controlling for environmental, socioeconomic, and urban morphology conditions across New York City tracts.</p><p><strong>Research Question:</strong> How does heat exposure influence urban livabilityâ€”as reflected in the proportion of QoL-related 311 service requestsâ€”across census tracts in New York City after accounting for environmental, socioeconomic, and urban morphology conditions?</p></div>
<div class="cell-markdown"><p><h4>1. Setup and Data Loading</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code># Import necessary libraries for data analysis and visualization.
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from matplotlib.patches import Rectangle
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.font_manager as fm
import seaborn as sns
from pathlib import Path
import warnings

# Spatial analysis libraries.
from libpysal.weights import KNN, Queen
from esda.moran import Moran, Moran_Local
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Suppress warnings for cleaner output.
warnings.filterwarnings(&quot;ignore&quot;)

# Set visualization parameters.
sns.set_style(&quot;whitegrid&quot;)
plt.rcParams[&quot;figure.figsize&quot;] = (12, 8)
plt.rcParams[&quot;font.size&quot;] = 10
plt.rcParams[&quot;axes.titlesize&quot;] = 14
plt.rcParams[&quot;axes.labelsize&quot;] = 12

# Set random seed for reproducibility.
np.random.seed(42)

# Font paths.
aleo_path = &quot;data/fonts/Aleo/Aleo-VariableFont_wght.ttf&quot;

# Register fonts.
fm.fontManager.addfont(aleo_path)

# Create FontProperties objects.
font_aleo = fm.FontProperties(fname = aleo_path)

# Global fonts.
plt.rcParams[&quot;font.family&quot;] = font_aleo.get_name()
plt.rcParams[&quot;axes.titleweight&quot;] = &quot;bold&quot;
plt.rcParams[&quot;axes.labelweight&quot;] = &quot;normal&quot;
plt.rcParams[&quot;font.size&quot;] = 12</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code># Load model data and spatial boundaries.
data_path = &quot;data/model/Final_Data_Model.csv&quot;
boundaries_path = &quot;data/nyc_city_boundary_land_only/nyc_city_boundary_land_only.shp&quot;
tracts_path = &quot;data/nyc_tracts_2020/nyc_tracts_2020.shp&quot;

# Read CSV data.
df = pd.read_csv(data_path)
print(f&quot;Dataset shape: {df.shape}&quot;)
print(f&quot;Total census tracts: {df.shape[0]}&quot;)
print(f&quot;Total features: {df.shape[1]}&quot;)

# Read spatial data.
boundaries = gpd.read_file(boundaries_path)
tracts = gpd.read_file(tracts_path)
tracts = tracts.rename(columns = {&quot;geoid&quot; : &quot;GEOID&quot;})

boundaries = boundaries.to_crs(tracts.crs)

print(f&quot;\nTracts shapefile loaded: {tracts.shape[0]} geometries&quot;)
print(f&quot;CRS: {tracts.crs}&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Dataset shape: (2225, 20)
Total census tracts: 2225
Total features: 20

Tracts shapefile loaded: 2325 geometries
CRS: GEOGCS[&quot;WGS84(DD)&quot;,DATUM[&quot;WGS84&quot;,SPHEROID[&quot;WGS84&quot;,6378137,298.257223563]],PRIMEM[&quot;Greenwich&quot;,0],UNIT[&quot;degree&quot;,0.0174532925199433],AXIS[&quot;Longitude&quot;,EAST],AXIS[&quot;Latitude&quot;,NORTH]]
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code># Merge data with spatial boundaries for mapping.
# Convert GEOID to string for consistent merging.
df[&quot;GEOID&quot;] = df[&quot;GEOID&quot;].astype(str)
tracts[&quot;GEOID&quot;] = tracts[&quot;GEOID&quot;].astype(str)

# Perform left join to keep all spatial geometries.
gdf = tracts.merge(df, on = &quot;GEOID&quot;, how = &quot;left&quot;)
print(f&quot;\nMerged GeoDataFrame shape: {gdf.shape}&quot;)
print(f&quot;Tracts with data: {gdf[&quot;TOTAL_POP_x&quot;].notna().sum()}&quot;)
print(f&quot;Tracts without data: {gdf[&quot;TOTAL_POP_x&quot;].isna().sum()}&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">
Merged GeoDataFrame shape: (2325, 33)
Tracts with data: 2225
Tracts without data: 100
</pre>
</div>
</div>

<div class="cell-markdown"><p><h4>2. Data Overview and Summary Statistics</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code># Display basic dataset information.
print(&quot;DATASET INFORMATION&quot;)

print(f&quot;\nTotal Observations: {len(df)}&quot;)
print(f&quot;Total Features: {len(df.columns)}&quot;)
print(f&quot;\nColumn Names:&quot;)

# Number them.
for i, col in enumerate(df.columns, 1):
    print(f&quot;{i:2d}. {col}&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">DATASET INFORMATION

Total Observations: 2225
Total Features: 20

Column Names:
 1. GEOID
 2. TOTAL_POP_x
 3. heatweek_avg_qol_calls
 4. normalweek_avg_qol_calls
 5. heatweek_calls_per_1k
 6. normalweek_calls_per_1k
 7. PCT_BACHELORS_PLUS
 8. PCT_RENTERS
 9. PCT_LIMITED_ENGLISH
10. MEDIAN_INCOME
11. POVERTY_RATE
12. PCT_NON_WHITE
13. PCT_TREE_CANOPY
14. PCT_IMPERVIOUS
15. WCR
16. NDVI
17. BD
18. AH
19. POI_500M_DENSITY
20. KNN_SUBWAY_dist_mean
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code># Examine data types and missing values.
print(&quot;DATA TYPES AND MISSING VALUES\n&quot;)

info_df = pd.DataFrame({
    &quot;Data Type&quot;: df.dtypes,
    &quot;Non-Null Count&quot;: df.count(),
    &quot;Null Count&quot;: df.isnull().sum(),
    &quot;Null Percentage&quot;: (df.isnull().sum() / len(df) * 100).round(2)
})

print(info_df.to_string())

# Highlight columns with missing values.
missing_cols = info_df[info_df[&quot;Null Count&quot;] &gt; 0]

if len(missing_cols) &gt; 0:
    print(&quot;\nColumns with missing values:&quot;)
    print(missing_cols[[&quot;Null Count&quot;, &quot;Null Percentage&quot;]].to_string())
else:
    print(&quot;\nNo missing values.&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">DATA TYPES AND MISSING VALUES

                         Data Type  Non-Null Count  Null Count  Null Percentage
GEOID                       object            2225           0              0.0
TOTAL_POP_x                float64            2225           0              0.0
heatweek_avg_qol_calls     float64            2225           0              0.0
normalweek_avg_qol_calls   float64            2225           0              0.0
heatweek_calls_per_1k      float64            2225           0              0.0
normalweek_calls_per_1k    float64            2225           0              0.0
PCT_BACHELORS_PLUS         float64            2225           0              0.0
PCT_RENTERS                float64            2225           0              0.0
PCT_LIMITED_ENGLISH        float64            2225           0              0.0
MEDIAN_INCOME                int64            2225           0              0.0
POVERTY_RATE               float64            2225           0              0.0
PCT_NON_W
... [truncated]</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 6</summary>
        <pre class="cell-code"><code># Define predictor categories based on project description.
# Socioeconomic and demographic predictors.
acs_predictors = [
    &quot;PCT_BACHELORS_PLUS&quot;,
    &quot;PCT_RENTERS&quot;,
    &quot;PCT_LIMITED_ENGLISH&quot;,
    &quot;MEDIAN_INCOME&quot;,
    &quot;POVERTY_RATE&quot;,
    &quot;PCT_NON_WHITE&quot;
]

# Environmental predictors.
env_predictors = [
    &quot;PCT_TREE_CANOPY&quot;,
    &quot;PCT_IMPERVIOUS&quot;,
    &quot;WCR&quot;,
    &quot;NDVI&quot;
]

# Urban form predictors.
urban_predictors = [
    &quot;BD&quot;,
    &quot;AH&quot;,
    &quot;POI_500M_DENSITY&quot;,
    &quot;KNN_SUBWAY_dist_mean&quot;
]

# Combined predictor set with all features.
all_predictors = env_predictors + acs_predictors + urban_predictors

# Target variables.
targets = [&quot;heatweek_calls_per_1k&quot;, &quot;normalweek_calls_per_1k&quot;]

# Additional call count variables.
call_vars = [&quot;heatweek_avg_qol_calls&quot;, &quot;normalweek_avg_qol_calls&quot;]

print(&quot;PREDICTOR CATEGORIES\n&quot;)

print(f&quot;Environmental Predictors: {len(env_predictors)}&quot;)
print(f&quot;Socioeconomic Predictors: {len(acs_predictors)}&quot;)
print(f&quot;Urban Form Predictors: {len(urban_predictors)}&quot;)
print(f&quot;Total Predictors: {len(all_predictors)}&quot;)
print(f&quot;Target Variables: {len(targets)}&quot;)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">PREDICTOR CATEGORIES

Environmental Predictors: 4
Socioeconomic Predictors: 6
Urban Form Predictors: 4
Total Predictors: 14
Target Variables: 2
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 7</summary>
        <pre class="cell-code"><code># Summary stats for all numeric variables.
print(&quot;SUMMARY STATS&quot;)

summary_all = df.describe().T
summary_all[&quot;skew&quot;] = df.skew(numeric_only = True)
summary_all[&quot;kurtosis&quot;] = df.kurtosis(numeric_only = True)

print(summary_all.to_string())</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">SUMMARY STATS
                           count          mean           std           min           25%           50%            75%            max       skew    kurtosis
TOTAL_POP_x               2225.0  3.872135e+03  1.949897e+03  5.700000e+01   2469.000000   3551.000000    4939.000000   15945.000000   1.142894    2.371892
heatweek_avg_qol_calls    2225.0  5.506854e+00  8.709629e+00  0.000000e+00      2.000000      3.800000       6.600000     180.200000  10.836368  165.185451
normalweek_avg_qol_calls  2225.0  5.985753e+00  8.759979e+00  0.000000e+00      2.428571      4.285714       7.142857     196.714286  11.084346  180.326227
heatweek_calls_per_1k     2225.0  1.793526e+00  4.224669e+00  0.000000e+00      0.577901      1.061477       1.890281     133.333333  17.769107  464.692226
normalweek_calls_per_1k   2225.0  1.892240e+00  3.661588e+00  0.000000e+00      0.729677      1.190285       1.998380      97.744361  13.517720  271.702411
PCT_BACHELORS_PLUS        2225.0  3.812916e-01  2.
... [truncated]</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 8</summary>
        <pre class="cell-code"><code># Summary stats by predictor category.
print(&quot;SUMMARY STATS - ENVIRONMENTAL PREDICTORS\n&quot;)
print(df[env_predictors].describe().T.to_string())

print(&quot;\nSUMMARY STATS - SOCIOECONOMIC PREDICTORS\n&quot;)
print(df[acs_predictors].describe().T.to_string())

print(&quot;\nSUMMARY STATS - URBAN FORM PREDICTORS\n&quot;)
print(df[urban_predictors].describe().T.to_string())

print(&quot;\nSUMMARY STATS - TARGET VARIABLES\n&quot;)
print(df[targets + call_vars].describe().T.to_string())</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">SUMMARY STATS - ENVIRONMENTAL PREDICTORS

                  count      mean       std       min       25%       50%       75%        max
PCT_TREE_CANOPY  2225.0  5.647950  7.548684  0.000000  0.844311  2.670270  8.112802  63.857995
PCT_IMPERVIOUS   2225.0  1.222685  0.181811  0.653538  1.086207  1.181818  1.316038   2.000000
WCR              2225.0  0.005148  0.029364  0.000000  0.000000  0.000000  0.000000   0.498365
NDVI             2225.0  0.061671  0.028007  0.006806  0.041246  0.056417  0.076770   0.192557

SUMMARY STATS - SOCIOECONOMIC PREDICTORS

                      count          mean           std          min           25%           50%            75%            max
PCT_BACHELORS_PLUS   2225.0  3.812916e-01  2.130461e-01          0.0      0.221082      0.335332       0.495343       0.943896
PCT_RENTERS          2225.0  6.257074e-01  2.543447e-01          0.0      0.441509      0.656321       0.834302       1.000000
PCT_LIMITED_ENGLISH  2225.0  6.222821e-03  1.202145e-02    
... [truncated]</pre>
</div>
</div>

<div class="cell-markdown"><p><h4>3. Univariate Analysis</h4></p></div>
<div class="cell-markdown"><p><h5>3.1 Target Variables Distribution</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 9</summary>
        <pre class="cell-code"><code># Distribution viz of target variables with histograms and KDE.
fig, axes = plt.subplots(2, 2, figsize = (14, 10))
fig.suptitle(&quot;Distribution of Target Variables\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;)

# Heat week calls per 1k.
axes[0, 0].hist(df[&quot;heatweek_calls_per_1k&quot;], bins = 50,
                edgecolor = &quot;white&quot;, alpha = 0.75, color = &quot;#b60101&quot;)

axes[0, 0].axvline(df[&quot;heatweek_calls_per_1k&quot;].mean(), color = &quot;red&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Mean: {df[&#x27;heatweek_calls_per_1k&#x27;].mean():.2f}&quot;)

axes[0, 0].axvline(df[&quot;heatweek_calls_per_1k&quot;].median(), color = &quot;orange&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Median: {df[&#x27;heatweek_calls_per_1k&#x27;].median():.2f}&quot;)

axes[0, 0].set_xlabel(&quot;Heat Week Calls per 1,000 Population&quot;)

axes[0, 0].set_ylabel(&quot;Frequency&quot;)

axes[0, 0].set_title(&quot;HEAT WEEK QOL CALLS PER 1K&quot;)

axes[0, 0].legend()

axes[0, 0].grid(alpha = 0.3)

# Normal week calls per 1k.
axes[0, 1].hist(df[&quot;normalweek_calls_per_1k&quot;], bins = 50,
                edgecolor = &quot;white&quot;, alpha = 0.75, color = &quot;#0101B6&quot;)

axes[0, 1].axvline(df[&quot;normalweek_calls_per_1k&quot;].mean(), color = &quot;red&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Mean: {df[&#x27;normalweek_calls_per_1k&#x27;].mean():.2f}&quot;)

axes[0, 1].axvline(df[&quot;normalweek_calls_per_1k&quot;].median(), color = &quot;orange&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Median: {df[&#x27;normalweek_calls_per_1k&#x27;].median():.2f}&quot;)

axes[0, 1].set_xlabel(&quot;Normal Week Calls per 1,000 Population&quot;)

axes[0, 1].set_ylabel(&quot;Frequency&quot;)

axes[0, 1].set_title(&quot;NORMAL WEEK QOL CALLS PER 1K&quot;)

axes[0, 1].legend()

axes[0, 1].grid(alpha = 0.3)

# Average QoL calls during heat weeks.
axes[1, 0].hist(df[&quot;heatweek_avg_qol_calls&quot;], bins = 50,
                edgecolor = &quot;white&quot;, alpha = 0.75, color = &quot;#b60101&quot;)

axes[1, 0].axvline(df[&quot;heatweek_avg_qol_calls&quot;].mean(), color = &quot;red&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Mean: {df[&#x27;heatweek_avg_qol_calls&#x27;].mean():.2f}&quot;)

axes[1, 0].axvline(df[&quot;heatweek_avg_qol_calls&quot;].median(), color = &quot;orange&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Median: {df[&#x27;heatweek_avg_qol_calls&#x27;].median():.2f}&quot;)

axes[1, 0].set_xlabel(&quot;Average Heat Week QoL Calls&quot;)

axes[1, 0].set_ylabel(&quot;Frequency&quot;)

axes[1, 0].set_title(&quot;HEAT WEEK AVERAGE QOL CALLS&quot;)

axes[1, 0].legend()

axes[1, 0].grid(alpha = 0.3)

# Average QoL calls during normal weeks.
axes[1, 1].hist(df[&quot;normalweek_avg_qol_calls&quot;], bins = 50,
                edgecolor = &quot;white&quot;, alpha = 0.75, color = &quot;#0101B6&quot;)

axes[1, 1].axvline(df[&quot;normalweek_avg_qol_calls&quot;].mean(), color = &quot;red&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Mean: {df[&#x27;normalweek_avg_qol_calls&#x27;].mean():.2f}&quot;)

axes[1, 1].axvline(df[&quot;normalweek_avg_qol_calls&quot;].median(), color = &quot;orange&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                   label = f&quot;Median: {df[&#x27;normalweek_avg_qol_calls&#x27;].median():.2f}&quot;)

axes[1, 1].set_xlabel(&quot;Average Normal Week QoL Calls&quot;)

axes[1, 1].set_ylabel(&quot;Frequency&quot;)

axes[1, 1].set_title(&quot;NORMAL WEEK AVERAGE QOL CALLS&quot;)

axes[1, 1].legend()

axes[1, 1].grid(alpha = 0.3)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>Mean difference (heat - normal): -0.0987 calls per 1k</p><p>Median difference: -0.1145 calls per 1k</p><p>Tracts with higher calls during heat weeks: 852 (38.3%)</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 10</summary>
        <pre class="cell-code"><code># Boxplot comparison of heat vs normal week calls.
fig, axes = plt.subplots(1, 2, figsize = (14, 6))
fig.suptitle(&quot;COMPARISON: HEAT WEEK VS NORMAL WEEK QOL CALLS\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;)

# Calls per 1k comparison.
box_data_1 = [df[&quot;heatweek_calls_per_1k&quot;].dropna(), df[&quot;normalweek_calls_per_1k&quot;].dropna()]

bp1 = axes[0].boxplot(box_data_1, labels = [&quot;Heat Week&quot;, &quot;Normal Week&quot;], patch_artist = True, widths = 0.6)

bp1[&quot;boxes&quot;][0].set_facecolor(&quot;orangered&quot;)

bp1[&quot;boxes&quot;][1].set_facecolor(&quot;steelblue&quot;)

for median in bp1[&quot;medians&quot;]:
    median.set_color(&quot;black&quot;)
    median.set_linewidth(2)

axes[0].set_ylabel(&quot;Calls per 1,000 Population&quot;)

axes[0].set_title(&quot;QOL CALLS PER 1K POPULATION&quot;)

axes[0].grid(alpha = 0.3, axis = &quot;y&quot;)

# Average calls comparison.
box_data_2 = [df[&quot;heatweek_avg_qol_calls&quot;].dropna(), df[&quot;normalweek_avg_qol_calls&quot;].dropna()]

bp2 = axes[1].boxplot(box_data_2, labels = [&quot;Heat Week&quot;, &quot;Normal Week&quot;], patch_artist = True, widths = 0.6)

bp2[&quot;boxes&quot;][0].set_facecolor(&quot;coral&quot;)

bp2[&quot;boxes&quot;][1].set_facecolor(&quot;skyblue&quot;)

for median in bp2[&quot;medians&quot;]:
    median.set_color(&quot;black&quot;)
    median.set_linewidth(2)

axes[1].set_ylabel(&quot;Average QoL Calls&quot;)

axes[1].set_title(&quot;AVERAGE QOL CALLS&quot;)

axes[1].grid(alpha = 0.3, axis = &quot;y&quot;)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>3.2 Environmental Predictors</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 11</summary>
        <pre class="cell-code"><code># Distribution viz of environmental predictors.
fig, axes = plt.subplots(2, 2, figsize = (14, 10))
fig.suptitle(&quot;DISTRIBUTION OF ENVIRONMENTAL PREDICTORS\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;)

colors = [&quot;forestgreen&quot;, &quot;gray&quot;, &quot;blue&quot;, &quot;darkgreen&quot;]

for idx, (var, color) in enumerate(zip(env_predictors, colors)):
    row = idx // 2
    col = idx % 2
    
    axes[row, col].hist(df[var].dropna(), bins = 50,
                        edgecolor = &quot;white&quot;, alpha = 0.75, color = color)
    
    axes[row, col].axvline(df[var].mean(), color = &quot;red&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                           label = f&quot;Mean: {df[var].mean():.2f}&quot;)
    
    axes[row, col].axvline(df[var].median(), color = &quot;orange&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                           label = f&quot;Median: {df[var].median():.2f}&quot;)
    
    axes[row, col].set_xlabel(var.replace(&quot;_&quot;, &quot; &quot;).upper())
    
    axes[row, col].set_ylabel(&quot;Frequency&quot;)

    axes[row, col].set_title(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].legend()

    axes[row, col].grid(alpha = 0.3)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>3.3 Socioeconomic Predictors</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 12</summary>
        <pre class="cell-code"><code># Distribution viz of socioeconomic predictors.
fig, axes = plt.subplots(3, 2, figsize = (14, 14))
fig.suptitle(&quot;DISTRIBUTION OF SOCIOECONOMIC PREDICTORS\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;)

colors = [&quot;purple&quot;, &quot;brown&quot;, &quot;pink&quot;, &quot;gold&quot;, &quot;crimson&quot;, &quot;teal&quot;]

for idx, (var, color) in enumerate(zip(acs_predictors, colors)):
    row = idx // 2
    col = idx % 2
    
    # Handle special case for MEDIAN_INCOME which may have placeholder values.
    data = df[var].copy()
    
    if var == &quot;MEDIAN_INCOME&quot;:
        data = data[data &gt; 0]  # Filter out negative placeholder values.
    
    axes[row, col].hist(data.dropna(), bins = 50,
                        edgecolor = &quot;white&quot;, alpha = 0.75, color = color)
    
    axes[row, col].axvline(data.mean(), color = &quot;red&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                           label = f&quot;Mean: {data.mean():.2f}&quot;)
    
    axes[row, col].axvline(data.median(), color = &quot;orange&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                           label = f&quot;Median: {data.median():.2f}&quot;)
    
    axes[row, col].set_xlabel(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].set_ylabel(&quot;Frequency&quot;)

    axes[row, col].set_title(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].legend()
    
    axes[row, col].grid(alpha = 0.3)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>3.4 Urban Form Predictors</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 13</summary>
        <pre class="cell-code"><code># Distribution viz of urban form predictors.
fig, axes = plt.subplots(2, 2, figsize = (14, 10))
fig.suptitle(&quot;DISTRIBUTION OF URBAN FORM PREDICTORS\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;)

colors = [&quot;navy&quot;, &quot;maroon&quot;, &quot;olive&quot;, &quot;indigo&quot;]

for idx, (var, color) in enumerate(zip(urban_predictors, colors)):
    row = idx // 2
    col = idx % 2
    
    axes[row, col].hist(df[var].dropna(),
                        bins = 50, edgecolor = &quot;white&quot;, alpha = 0.75, color = color)
    
    axes[row, col].axvline(df[var].mean(), color = &quot;red&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                           label = f&quot;Mean: {df[var].mean():.2f}&quot;)
    
    axes[row, col].axvline(df[var].median(), color = &quot;orange&quot;, linestyle = &quot;--&quot;, linewidth = 2,
                           label = f&quot;Median: {df[var].median():.2f}&quot;)
    
    axes[row, col].set_xlabel(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].set_ylabel(&quot;Frequency&quot;)

    axes[row, col].set_title(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].legend()
    
    axes[row, col].grid(alpha = 0.3)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h4>4. Bivariate Analysis</h4></p></div>
<div class="cell-markdown"><p><h5>4.1 Correlation Analysis</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 14</summary>
        <pre class="cell-code"><code># Correlation matrix for all predictors and targets.
analysis_vars = targets + all_predictors
corr_matrix = df[analysis_vars].corr()

# Correlation matrix viz with heatmap.
fig, ax = plt.subplots(figsize = (16, 14))

mask = np.triu(np.ones_like(corr_matrix, dtype = bool))

sns.heatmap(corr_matrix, mask = mask, annot = True, fmt = &quot;.2f&quot;, cmap = &quot;RdBu_r&quot;, 
            center = 0, vmin = -1, vmax = 1, square = True, linewidths = 0.5,
            cbar_kws = {&quot;shrink&quot;: 0.8}, ax = ax)

ax.set_title(&quot;CORRELATION MATRIX: TARGETS AND ALL PREDICTORS\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;, pad = 20)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 15</summary>
        <pre class="cell-code"><code># Correlation of predictors with target variables.
print(&quot;CORRELATIONS WITH TARGET VARIABLES\n&quot;)

target_corrs = pd.DataFrame({
    &quot;Heat Week Calls&quot;: corr_matrix[&quot;heatweek_calls_per_1k&quot;][all_predictors],
    &quot;Normal Week Calls&quot;: corr_matrix[&quot;normalweek_calls_per_1k&quot;][all_predictors]
})

target_corrs[&quot;Difference&quot;] = target_corrs[&quot;Heat Week Calls&quot;] - target_corrs[&quot;Normal Week Calls&quot;]

target_corrs = target_corrs.sort_values(&quot;Heat Week Calls&quot;, key = abs, ascending = False)

print(target_corrs.to_string())

# Visualize top correlations with targets.
fig, axes = plt.subplots(1, 2, figsize = (16, 8))

# Heat week correlations.
top_n = 10
top_heat = target_corrs[&quot;Heat Week Calls&quot;].sort_values(key = abs, ascending = False).head(top_n)
colors_heat = [&quot;orangered&quot; if x &gt; 0 else &quot;steelblue&quot; for x in top_heat.values]

axes[0].barh(range(len(top_heat)), top_heat.values,
             color = colors_heat, edgecolor = &quot;white&quot;)

axes[0].set_yticks(range(len(top_heat)))

axes[0].set_yticklabels(top_heat.index)

axes[0].set_xlabel(&quot;Correlation Coefficient&quot;)

axes[0].set_title(f&quot;TOP {top_n} PREDICTORS CORRELATED WITH HEAT WEEK CALLS\n&quot;, fontweight = &quot;bold&quot;)

axes[0].axvline(0, color = &quot;black&quot;, linewidth = 1)

axes[0].grid(alpha = 0.3, axis = &quot;x&quot;)

# Normal week correlations.
top_normal = target_corrs[&quot;Normal Week Calls&quot;].sort_values(key = abs, ascending = False).head(top_n)
colors_normal = [&quot;orangered&quot; if x &gt; 0 else &quot;steelblue&quot; for x in top_normal.values]

axes[1].barh(range(len(top_normal)), top_normal.values,
             color = colors_normal, edgecolor = &quot;white&quot;)

axes[1].set_yticks(range(len(top_normal)))

axes[1].set_yticklabels(top_normal.index)

axes[1].set_xlabel(&quot;Correlation Coefficient&quot;)

axes[1].set_title(f&quot;TOP {top_n} PREDICTORS CORRELATED WITH NORMAL WEEK CALLS\n&quot;, fontweight = &quot;bold&quot;)

axes[1].axvline(0, color = &quot;black&quot;, linewidth = 1)

axes[1].grid(alpha = 0.3, axis = &quot;x&quot;)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">CORRELATIONS WITH TARGET VARIABLES

                      Heat Week Calls  Normal Week Calls  Difference
MEDIAN_INCOME               -0.198402          -0.185367   -0.013035
NDVI                        -0.105720          -0.113270    0.007550
AH                           0.072747           0.072362    0.000385
PCT_IMPERVIOUS               0.067571           0.060007    0.007564
PCT_NON_WHITE               -0.058319          -0.061150    0.002831
PCT_TREE_CANOPY             -0.054636          -0.063440    0.008804
BD                           0.048339           0.063436   -0.015096
PCT_BACHELORS_PLUS           0.045007           0.058821   -0.013814
POI_500M_DENSITY             0.035472           0.045540   -0.010068
KNN_SUBWAY_dist_mean        -0.028824          -0.048551    0.019727
PCT_RENTERS                  0.014312           0.020747   -0.006435
WCR                          0.014266           0.007046    0.007219
POVERTY_RATE                 0.014119          -0.001531    0.01565
... [truncated]</pre>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>4.2 Scatterplots: Key Relationships</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 16</summary>
        <pre class="cell-code"><code># Scatterplots of environmental predictors vs heat week calls.
fig, axes = plt.subplots(2, 2, figsize = (14, 12))
fig.suptitle(&quot;ENVIRONMENTAL PREDICTORS VS HEAT WEEK QOL CALLS PER 1K\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;)

for idx, var in enumerate(env_predictors):
    row = idx // 2
    col = idx % 2
    
    axes[row, col].scatter(df[var], df[&quot;heatweek_calls_per_1k&quot;], alpha = 0.5, s = 20,
                           color = &quot;orangered&quot;, edgecolors = &quot;black&quot;, linewidth = 0.3)
    
    # Add regression line.
    valid_mask = df[var].notna() &amp; df[&quot;heatweek_calls_per_1k&quot;].notna()

    if valid_mask.sum() &gt; 1:
        z = np.polyfit(df.loc[valid_mask, var], df.loc[valid_mask, &quot;heatweek_calls_per_1k&quot;], 1)
        p = np.poly1d(z)
        x_line = np.linspace(df[var].min(), df[var].max(), 100)
        axes[row, col].plot(x_line, p(x_line), &quot;b--&quot;, linewidth = 1.5,
                            label = f&quot;Trend (r={corr_matrix.loc[var, &#x27;heatweek_calls_per_1k&#x27;]:.3f})&quot;)
    
    axes[row, col].set_xlabel(var.replace(&quot;_&quot;, &quot; &quot;).upper())
    
    axes[row, col].set_ylabel(&quot;Heat Week Calls per 1k&quot;)

    axes[row, col].set_title(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].legend()

    axes[row, col].grid(alpha = 0.3)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 17</summary>
        <pre class="cell-code"><code># Scatterplots of socioeconomic predictors vs heat week calls.
fig, axes = plt.subplots(3, 2, figsize = (14, 16))
fig.suptitle(&quot;SOCIOECONOMIC PREDICTORS VS HEAT WEEK QOL CALLS PER 1K\n&quot;, fontsize = 16, fontweight = &quot;bold&quot;)

for idx, var in enumerate(acs_predictors):
    row = idx // 2
    col = idx % 2
    
    # Handle special case for MEDIAN_INCOME.
    if var == &quot;MEDIAN_INCOME&quot;:
        plot_data = df[df[var] &gt; 0]
    else:
        plot_data = df
    
    axes[row, col].scatter(plot_data[var], plot_data[&quot;heatweek_calls_per_1k&quot;], alpha = 0.5, s = 20,
                           color = &quot;coral&quot;, edgecolors = &quot;black&quot;, linewidth = 0.3)
    
    # Add regression line.
    valid_mask = plot_data[var].notna() &amp; plot_data[&quot;heatweek_calls_per_1k&quot;].notna()
    
    if valid_mask.sum() &gt; 1:
        z = np.polyfit(plot_data.loc[valid_mask, var], plot_data.loc[valid_mask, &quot;heatweek_calls_per_1k&quot;], 1)
        p = np.poly1d(z)
        x_line = np.linspace(plot_data[var].min(), plot_data[var].max(), 100)
        axes[row, col].plot(x_line, p(x_line), &quot;b--&quot;, linewidth = 1.5,
                            label = f&quot;Trend (r={corr_matrix.loc[var, &#x27;heatweek_calls_per_1k&#x27;]:.3f})&quot;)
    
    axes[row, col].set_xlabel(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].set_ylabel(&quot;Heat Week Calls per 1k&quot;)

    axes[row, col].set_title(var.replace(&quot;_&quot;, &quot; &quot;).upper())

    axes[row, col].legend()

    axes[row, col].grid(alpha = 0.3)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 18</summary>
        <pre class="cell-code"><code># Direct comparison scatterplot: Heat week vs Normal week calls.
fig, ax = plt.subplots(figsize = (10, 10))

df[&quot;calls_per_1k_diff&quot;] = (
    df[&quot;heatweek_calls_per_1k&quot;] - df[&quot;normalweek_calls_per_1k&quot;]
)

ax.scatter(df[&quot;normalweek_calls_per_1k&quot;], df[&quot;heatweek_calls_per_1k&quot;], 
           alpha = 0.6, s = 30, c = df[&quot;calls_per_1k_diff&quot;], 
           cmap = &quot;RdBu_r&quot;, edgecolors = &quot;black&quot;, linewidth = 0.5)

# Add diagonal reference line.
max_val = max(df[&quot;normalweek_calls_per_1k&quot;].max(), df[&quot;heatweek_calls_per_1k&quot;].max())

ax.plot([0, max_val], [0, max_val], &quot;k--&quot;, linewidth = 1, label = &quot;Equal calls (y=x)&quot;)

ax.set_xlabel(&quot;Normal Week Calls per 1k&quot;, fontsize = 12)

ax.set_ylabel(&quot;Heat Week Calls per 1k&quot;, fontsize = 12)

ax.set_title(&quot;HEAT WEEK VS NORMAL WEEK QOL CALLS PER 1K\n(Color = Difference)\n&quot;,
             fontsize = 14, fontweight = &quot;bold&quot;)

ax.legend()

ax.grid(alpha = 0.3)

cbar = plt.colorbar(ax.collections[0], ax = ax)
cbar.set_label(&quot;Difference (Heat - Normal)&quot;, rotation = 270, labelpad = 20)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>Tracts above diagonal (more calls during heat): 852 (38.3%)</p><p>Tracts below diagonal (fewer calls during heat): 1356 (60.9%)</p><p>Tracts on diagonal (equal calls): 17 (0.8%)</p></div>
<div class="cell-markdown"><p><h4>5. Multicollinearity Assessment</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 19</summary>
        <pre class="cell-code"><code># Prepare data for VIF calculation.
# Drop rows with missing values in predictors.
vif_data = df[all_predictors].copy()

# Handle MEDIAN_INCOME placeholder values.
if &quot;MEDIAN_INCOME&quot; in vif_data.columns:
    vif_data.loc[vif_data[&quot;MEDIAN_INCOME&quot;] &lt; 0, &quot;MEDIAN_INCOME&quot;] = np.nan

vif_data = vif_data.dropna()

# Calculate VIF for each predictor.
vif_results = pd.DataFrame()
vif_results[&quot;Variable&quot;] = all_predictors
vif_results[&quot;VIF&quot;] = [variance_inflation_factor(vif_data.values, i) for i in range(len(all_predictors))]
vif_results = vif_results.sort_values(&quot;VIF&quot;, ascending = False)

# Add warning flags.
vif_results[&quot;Flag&quot;] = vif_results[&quot;VIF&quot;].apply(lambda x: &quot;HIGH&quot; if x &gt; 10 else (&quot;MODERATE&quot; if x &gt; 5 else &quot;OK&quot;))

print(vif_results.to_string(index = False))</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">            Variable       VIF     Flag
      PCT_IMPERVIOUS 53.829286     HIGH
                  BD 24.335496     HIGH
  PCT_BACHELORS_PLUS 19.086784     HIGH
         PCT_RENTERS 18.630721     HIGH
       MEDIAN_INCOME 17.783552     HIGH
                NDVI 12.859890     HIGH
       PCT_NON_WHITE 10.022016     HIGH
        POVERTY_RATE  6.621613 MODERATE
KNN_SUBWAY_dist_mean  5.033824 MODERATE
     PCT_TREE_CANOPY  4.609767       OK
                  AH  4.335747       OK
    POI_500M_DENSITY  3.327035       OK
 PCT_LIMITED_ENGLISH  1.580739       OK
                 WCR  1.130999       OK
</pre>
</div>
</div>

<div class="cell-markdown"><p>VIF > 10 suggests high multicollinearity.</p><p>VIF > 5 may warrant investigation.</p><p>14 predictors and ~2200 observations.</p><p>7 variable(s) with VIF > 10 (high multicollinearity)</p><p>2 variable(s) with 5 < VIF <= 10 (moderate multicollinearity)</p><p>5 variable(s) with VIF <= 5 (acceptable)</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 20</summary>
        <pre class="cell-code"><code># VIF values viz.
fig, ax = plt.subplots(figsize = (12, 8))

colors = [&quot;red&quot; if x &gt; 10 else &quot;orange&quot; if x &gt; 5 else &quot;green&quot; for x in vif_results[&quot;VIF&quot;]]

bars = ax.barh(range(len(vif_results)), vif_results[&quot;VIF&quot;], color = colors, edgecolor = &quot;white&quot;, alpha = 0.75)

ax.set_yticks(range(len(vif_results)))

ax.set_yticklabels(vif_results[&quot;Variable&quot;])

ax.set_xlabel(&quot;Variance Inflation Factor (VIF)&quot;, fontsize = 12)

ax.set_title(&quot;MULTICOLLINEARITY ASSESSMENT: VIF FOR ALL PREDICTORS\n\n&quot;,
             fontsize = 14, fontweight = &quot;bold&quot;)

ax.axvline(5, color = &quot;black&quot;, linestyle = &quot;--&quot;, linewidth = 1.5,
           label = &quot;VIF = 5 (moderate threshold)&quot;)

ax.axvline(10, color = &quot;blue&quot;, linestyle = &quot;--&quot;, linewidth = 1.5,
           label = &quot;VIF = 10 (high threshold)&quot;)

ax.legend()

ax.grid(alpha = 0.3, axis = &quot;x&quot;)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h4>6. Spatial Analysis and Visualization</h4></p></div>
<div class="cell-markdown"><p><h5>6.1 Choropleth Maps of Key Variables</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 21</summary>
        <pre class="cell-code"><code># Helper function to plot maps.
def plot_map(ax, column, cmap, title, gdf_source, vmin = None, vmax = None):
    gdf_source.plot(
        column = column,
        cmap = cmap,
        legend = True,
        ax = ax,
        linewidth = 0,
        edgecolor = &quot;face&quot;,
        antialiased = False,
        rasterized = True,
        missing_kwds = {&quot;color&quot;: &quot;lightgrey&quot;},
        vmin = vmin,
        vmax = vmax
    )
    
    boundaries.plot(
        ax = ax,
        facecolor = &quot;none&quot;,
        edgecolor = &quot;#9b9e98&quot;,
        linewidth = 1
    )

    ax.set_title(
        title,
        fontsize = 20,
        fontproperties = font_aleo,
        fontweight = &quot;bold&quot;,
        pad = 12
    )

    ax.axis(&quot;off&quot;)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 22</summary>
        <pre class="cell-code"><code>fig, axes = plt.subplots(2, 2, figsize = (18, 16))
fig.suptitle(
    &quot;SPATIAL DISTRIBUTION OF QOL CALLS PER 1K POPULATION\n\n&quot;,
    fontsize = 18,
    fontweight = &quot;bold&quot;
)

# 1. Heat week calls.
plot_map(
    axes[0, 0],
    &quot;heatweek_calls_per_1k&quot;,
    &quot;YlOrRd&quot;,
    &quot;HEAT WEEK QOL CALLS PER 1K&quot;,
    gdf
)

# 2. Normal week calls.
plot_map(
    axes[0, 1],
    &quot;normalweek_calls_per_1k&quot;,
    &quot;PuBu&quot;,
    &quot;NORMAL WEEK QOL CALLS PER 1K&quot;,
    gdf
)

# 3. Difference (heat â€“ normal).
gdf[&quot;calls_per_1k_diff&quot;] = (
    gdf[&quot;heatweek_calls_per_1k&quot;] - gdf[&quot;normalweek_calls_per_1k&quot;]
)

diff = gdf[&quot;calls_per_1k_diff&quot;]
max_abs = np.nanmax(np.abs(diff))

plot_map(
    axes[1, 0],
    &quot;calls_per_1k_diff&quot;,
    &quot;RdBu_r&quot;,
    &quot;DIFFERENCE: HEAT WEEK â€“ NORMAL WEEK&quot;,
    gdf,
    vmin = -max_abs,
    vmax = max_abs
)

# Percent change.
gdf[&quot;pct_change&quot;] = (
    (gdf[&quot;heatweek_calls_per_1k&quot;] - gdf[&quot;normalweek_calls_per_1k&quot;])
    / gdf[&quot;normalweek_calls_per_1k&quot;].replace(0, np.nan)
) * 100

pct = gdf[&quot;pct_change&quot;].clip(-200, 200)
gdf[&quot;pct_change_clipped&quot;] = pct

plot_map(
    axes[1, 1],
    &quot;pct_change&quot;,
    &quot;RdBu_r&quot;,
    &quot;PERCENT CHANGE: HEAT VS NORMAL WEEK&quot;,
    gdf,
    vmin = -200,
    vmax = 200
)

plt.tight_layout()
plt.show()
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 23</summary>
        <pre class="cell-code"><code>fig, axes = plt.subplots(2, 2, figsize = (18, 16))
fig.suptitle(
    &quot;SPATIAL DISTRIBUTION OF ENVIRONMENTAL PREDICTORS\n\n&quot;,
    fontsize = 18,
    fontweight = &quot;bold&quot;
)

cmaps = [&quot;Greens&quot;, &quot;Reds&quot;, &quot;Blues&quot;, &quot;YlGn&quot;]

for idx, (var, cmap) in enumerate(zip(env_predictors, cmaps)):
    row = idx // 2
    col = idx % 2
    
    title = var.replace(&quot;_&quot;, &quot; &quot;).upper()
    plot_map(axes[row, col], var, cmap, title, gdf)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 24</summary>
        <pre class="cell-code"><code>fig, axes = plt.subplots(3, 2, figsize = (18, 20))
fig.suptitle(
    &quot;SPATIAL DISTRIBUTION OF SOCIOECONOMIC PREDICTORS\n\n&quot;,
    fontsize = 18,
    fontweight = &quot;bold&quot;
)

cmaps = [&quot;Purples&quot;, &quot;copper_r&quot;, &quot;PuRd&quot;, &quot;YlGnBu&quot;, &quot;Oranges&quot;, &quot;BuPu&quot;]

for idx, (var, cmap) in enumerate(zip(acs_predictors, cmaps)):
    row = idx // 2
    col = idx % 2
    
    # Handle MEDIAN_INCOME.
    if var == &quot;MEDIAN_INCOME&quot;:
        plot_gdf = gdf.copy()
        plot_gdf.loc[plot_gdf[var] &lt; 0, var] = np.nan
    else:
        plot_gdf = gdf
    
    title = var.replace(&quot;_&quot;, &quot; &quot;).upper()
    plot_map(axes[row, col], var, cmap, title, plot_gdf)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 25</summary>
        <pre class="cell-code"><code>fig, axes = plt.subplots(2, 2, figsize = (18, 16))
fig.suptitle(
    &quot;SPATIAL DISTRIBUTION OF URBAN FORM PREDICTORS\n\n&quot;,
    fontsize = 18,
    fontweight = &quot;bold&quot;
)

cmaps = [&quot;viridis&quot;, &quot;plasma&quot;, &quot;magma&quot;, &quot;magma_r&quot;]

for idx, (var, cmap) in enumerate(zip(urban_predictors, cmaps)):
    row = idx // 2
    col = idx % 2
    
    title = var.replace(&quot;_&quot;, &quot; &quot;).upper()
    plot_map(axes[row, col], var, cmap, title, gdf)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>6.2 Spatial Autocorrelation Analysis</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 26</summary>
        <pre class="cell-code"><code># Prepare spatial weights matrix using Queen contiguity.
# Remove tracts without data for spatial weights calculation.
gdf_complete = gdf.dropna(subset = [&quot;heatweek_calls_per_1k&quot;])
w = Queen.from_dataframe(gdf_complete)
w.transform = &quot;r&quot;  # Row-standardization.

# Calculate Moran&#x27;s I for selected variables.
test_vars = targets + [&quot;calls_per_1k_diff&quot;] + env_predictors[:2] + acs_predictors[:2]
morans_results = []

for var in test_vars:
    if var in gdf_complete.columns and gdf_complete[var].notna().sum() &gt; 0:
        try:
            mi = Moran(gdf_complete[var], w)
            morans_results.append({
                &quot;Variable&quot;: var,
                &quot;Moran&#x27;s I&quot;: mi.I,
                &quot;Expected I&quot;: mi.EI,
                &quot;p-value&quot;: mi.p_sim,
                &quot;Significant&quot;: &quot;Yes&quot; if mi.p_sim &lt; 0.05 else &quot;No&quot;
            })
        except:
            continue

morans_df = pd.DataFrame(morans_results)
print(morans_df.to_string(index = False))</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">(&#x27;WARNING: &#x27;, 815, &#x27; is an island (no neighbors)&#x27;)
(&#x27;WARNING: &#x27;, 1635, &#x27; is an island (no neighbors)&#x27;)
(&#x27;WARNING: &#x27;, 2036, &#x27; is an island (no neighbors)&#x27;)
               Variable  Moran&#x27;s I  Expected I  p-value Significant
  heatweek_calls_per_1k   0.163050    -0.00045    0.001         Yes
normalweek_calls_per_1k   0.192314    -0.00045    0.001         Yes
      calls_per_1k_diff   0.015316    -0.00045    0.070          No
        PCT_TREE_CANOPY   0.639520    -0.00045    0.001         Yes
         PCT_IMPERVIOUS   0.557429    -0.00045    0.001         Yes
     PCT_BACHELORS_PLUS   0.791766    -0.00045    0.001         Yes
            PCT_RENTERS   0.654061    -0.00045    0.001         Yes
</pre>
</div>
</div>

<div class="cell-markdown"><p>Spatial weights created for 2225 tracts.</p><p>Average number of neighbors: 5.87.</p><p>Moran's I ranges from -1 (dispersed) to +1 (clustered). Values near 0 indicate random spatial pattern.</p><p>Positive Moran's I indicates spatial clustering (similar values near each other).</p><p>Negative Moran's I indicates spatial dispersion (dissimilar values near each other).</p><p>p-value < 0.05 indicates statistically significant spatial pattern.</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 27</summary>
        <pre class="cell-code"><code># Calculate Local Moran&#x27;s I.
lisa = Moran_Local(gdf_complete[&quot;heatweek_calls_per_1k&quot;], w)

# Add LISA results to geodataframe.
gdf_complete[&quot;lisa_cluster&quot;] = lisa.q
gdf_complete[&quot;lisa_pval&quot;] = lisa.p_sim
gdf_complete[&quot;lisa_sig&quot;] = (lisa.p_sim &lt; 0.05).astype(int)

# Create cluster labels.
cluster_labels = {
    1: &quot;HH (High-High)&quot;,
    2: &quot;LH (Low-High)&quot;,
    3: &quot;LL (Low-Low)&quot;,
    4: &quot;HL (High-Low)&quot;,
    0: &quot;Not Significant&quot;
}

# Filter for significant clusters only.
gdf_complete[&quot;lisa_label&quot;] = gdf_complete.apply(
    lambda row: cluster_labels[row[&quot;lisa_cluster&quot;]] if row[&quot;lisa_sig&quot;] == 1 else cluster_labels[0],
    axis = 1
)

# Summary of clusters.
cluster_summary = gdf_complete[&quot;lisa_label&quot;].value_counts()
print(&quot;\nLISA Cluster Summary:&quot;)
print(cluster_summary.to_string())

# Map LISA clusters.
fig, ax = plt.subplots(figsize = (14, 12))

# Define colors for clusters.
cluster_colors = {
    &quot;HH (High-High)&quot;: &quot;#d7191d&quot;,
    &quot;LL (Low-Low)&quot;: &quot;#2c7bb6&quot;,
    &quot;LH (Low-High)&quot;: &quot;#fcaf60&quot;,
    &quot;HL (High-Low)&quot;: &quot;#abd8e9&quot;,
    &quot;Not Significant&quot;: &quot;lightgray&quot;
}

for label, color in cluster_colors.items():
    subset = gdf_complete[gdf_complete[&quot;lisa_label&quot;] == label]
    if len(subset) &gt; 0:
        subset.plot(ax = ax, color = color, edgecolor = &quot;white&quot;, linewidth = 0.5, label = label)

ax.set_title(&quot;LISA CLUSTER MAP: HEAT WEEK QOL CALLS PER 1K\n(Significant Clusters at p &lt; 0.05)&quot;, 
             fontsize = 14, fontweight = &quot;bold&quot;)
ax.axis(&quot;off&quot;)
ax.legend(loc = &quot;upper left&quot;, fontsize = 10)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">
LISA Cluster Summary:
lisa_label
Not Significant    1754
LL (Low-Low)        324
HH (High-High)       86
LH (Low-High)        44
HL (High-Low)        17
</pre>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>HH (High-High): Hot spots - high values surrounded by high values.</p><p>LL (Low-Low): Cold spots - low values surrounded by low values.</p><p>LH (Low-High): Spatial outliers - low values surrounded by high values.</p><p>HL (High-Low): Spatial outliers - high values surrounded by low values.</p></div>
<div class="cell-markdown"><p><h5>6.3 Bivariate Choropleth Maps</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 28</summary>
        <pre class="cell-code"><code># Function to create bivariate choropleth map.
def create_bivariate_map(gdf, var1, var2, title, var1_label, var2_label):
    &quot;&quot;&quot;
    Create bivariate choropleth map showing relationship between two variables.
    
    Parameters:
    - gdf: GeoDataFrame with spatial data.
    - var1: First variable name (string).
    - var2: Second variable name (string).
    - title: Map title (string).
    - var1_label: Label for first variable (string).
    - var2_label: Label for second variable (string).
    &quot;&quot;&quot;
    
    # Create copy and remove missing values.
    plot_gdf = gdf[[var1, var2, &quot;geometry&quot;]].copy().dropna()
    
    # Classify each variable into 3 quantiles.
    plot_gdf[f&quot;{var1}_class&quot;] = pd.qcut(plot_gdf[var1], q = 3, labels = [&quot;Low&quot;, &quot;Med&quot;, &quot;High&quot;], duplicates = &quot;drop&quot;)
    plot_gdf[f&quot;{var2}_class&quot;] = pd.qcut(plot_gdf[var2], q = 3, labels = [&quot;Low&quot;, &quot;Med&quot;, &quot;High&quot;], duplicates = &quot;drop&quot;)
    
    # Create bivariate class.
    plot_gdf[&quot;bivar_class&quot;] = plot_gdf[f&quot;{var1}_class&quot;].astype(str) + &quot;-&quot; + plot_gdf[f&quot;{var2}_class&quot;].astype(str)
    
    # Define color scheme for 3x3 bivariate map.
    color_dict = {
        &quot;Low-Low&quot;: &quot;#e8e8e8&quot;,
        &quot;Low-Med&quot;: &quot;#ace4e4&quot;,
        &quot;Low-High&quot;: &quot;#5ac8c8&quot;,
        &quot;Med-Low&quot;: &quot;#dfb0d6&quot;,
        &quot;Med-Med&quot;: &quot;#a5add3&quot;,
        &quot;Med-High&quot;: &quot;#5698b9&quot;,
        &quot;High-Low&quot;: &quot;#be64ac&quot;,
        &quot;High-Med&quot;: &quot;#8c62aa&quot;,
        &quot;High-High&quot;: &quot;#3b4994&quot;
    }
    
    # Map colors.
    plot_gdf[&quot;color&quot;] = plot_gdf[&quot;bivar_class&quot;].map(color_dict)
    
    # Create plot.
    fig, ax = plt.subplots(figsize = (14, 12))

    plot_gdf.plot(color = plot_gdf[&quot;color&quot;], ax = ax, edgecolor = &quot;white&quot;, linewidth = 0.5)

    ax.set_title(title, fontsize = 14, fontweight = &quot;bold&quot;)

    ax.axis(&quot;off&quot;)
    
    legend_elements = []

    for key, color in color_dict.items():
        legend_elements.append(Rectangle((0, 0), 1, 1, facecolor = color, edgecolor = &quot;none&quot;, label = key))
    
    ax.legend(handles = legend_elements, title = f&quot;{var1_label} - {var2_label}&quot;, 
              loc = &quot;upper left&quot;, fontsize = 8, ncol = 3)
    
    plt.tight_layout()
    plt.show()
    
    return plot_gdf</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 29</summary>
        <pre class="cell-code"><code># Bivariate map: Heat week calls vs Average building height.
bivar_gdf1 = create_bivariate_map(
    gdf,
    &quot;heatweek_calls_per_1k&quot;,
    &quot;AH&quot;,
    &quot;BIVARIATE MAP: HEAT WEEK CALLS PER 1K VS AVERAGE BUILDING HEIGHT\n&quot;,
    &quot;Heat Calls&quot;,
    &quot;Average Building Height&quot;
)</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 30</summary>
        <pre class="cell-code"><code># Bivariate map: Heat week calls vs Tree canopy.
bivar_gdf1 = create_bivariate_map(
    gdf,
    &quot;heatweek_calls_per_1k&quot;,
    &quot;PCT_NON_WHITE&quot;,
    &quot;BIVARIATE MAP: HEAT WEEK CALLS PER 1K VS PERCENT NON-WHITE\n&quot;,
    &quot;Heat Calls&quot;,
    &quot;Percent Non-White&quot;
)</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 31</summary>
        <pre class="cell-code"><code># Bivariate map: Heat week calls vs Median income.
# Filter out placeholder income values.
gdf_income = gdf.copy()
gdf_income.loc[gdf_income[&quot;MEDIAN_INCOME&quot;] &lt; 0, &quot;MEDIAN_INCOME&quot;] = np.nan

bivar_gdf2 = create_bivariate_map(
    gdf_income,
    &quot;heatweek_calls_per_1k&quot;,
    &quot;MEDIAN_INCOME&quot;,
    &quot;BIVARIATE MAP: HEAT WEEK CALLS PER 1K VS MEDIAN INCOME\n&quot;,
    &quot;Heat Calls&quot;,
    &quot;Median Income&quot;
)</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 32</summary>
        <pre class="cell-code"><code># Bivariate map: Heat week calls vs NDVI.
bivar_gdf3 = create_bivariate_map(
    gdf,
    &quot;heatweek_calls_per_1k&quot;,
    &quot;NDVI&quot;,
    &quot;BIVARIATE MAP: HEAT WEEK CALLS PER 1K VS NDVI&quot;,
    &quot;Heat Calls&quot;,
    &quot;NDVI&quot;
)</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 33</summary>
        <pre class="cell-code"><code># Bivariate map: Heat week calls vs Subway distance.
bivar_gdf3 = create_bivariate_map(
    gdf,
    &quot;heatweek_calls_per_1k&quot;,
    &quot;KNN_SUBWAY_dist_mean&quot;,
    &quot;BIVARIATE MAP: HEAT WEEK CALLS PER 1K VS AVERAGE SUBWAY DISTANCE&quot;,
    &quot;Heat Calls&quot;,
    &quot;Average Subway Distance&quot;
)</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h4>7. Key Findings and Data Quality Notes</h4></p></div>
<div class="cell-markdown"><p>KEY EXPLORATORY DATA ANALYSIS FINDINGS</p><p>- TARGET VARIABLE CHARACTERISTICS:</p><p>- Mean heat week calls per 1k: 1.794</p><p>- Mean normal week calls per 1k: 1.892</p><p>- Mean difference: -0.099 (-5.2% decrease), likely due to the significantly smaller number of weeks and difference in super-users</p><p>- Tracts with increased calls during heat: 852 (38.3%)</p><p>- STRONGEST CORRELATIONS WITH HEAT WEEK CALLS:</p><p>- MEDIAN_INCOME: -0.198</p><p>- NDVI: -0.106</p><p>- AH: 0.073</p><p>- PCT_IMPERVIOUS: 0.068</p><p>- PCT_NON_WHITE: -0.058</p><p>- MULTICOLLINEARITY CONCERNS:</p><p>- 7 variables with VIF > 10:</p><p>â€¢ PCT_IMPERVIOUS: VIF = 53.83</p><p>â€¢ BD: VIF = 24.34</p><p>â€¢ PCT_BACHELORS_PLUS: VIF = 19.09</p><p>â€¢ PCT_RENTERS: VIF = 18.63</p><p>â€¢ MEDIAN_INCOME: VIF = 17.78</p><p>â€¢ NDVI: VIF = 12.86</p><p>â€¢ PCT_NON_WHITE: VIF = 10.02</p><p>- SPATIAL PATTERNS:</p><p>- 6 variable(s) show significant spatial autocorrelation:</p><p>â€¢ heatweek_calls_per_1k: Moran's I = 0.163 (p = 0.0010)</p><p>â€¢ normalweek_calls_per_1k: Moran's I = 0.192 (p = 0.0010)</p><p>â€¢ PCT_TREE_CANOPY: Moran's I = 0.640 (p = 0.0010)</p><p>â€¢ PCT_IMPERVIOUS: Moran's I = 0.557 (p = 0.0010)</p><p>â€¢ PCT_BACHELORS_PLUS: Moran's I = 0.792 (p = 0.0010)</p><p>â€¢ PCT_RENTERS: Moran's I = 0.654 (p = 0.0010)</p><p>- LISA Hot Spots (HH): 86 tracts</p><p>- LISA Cold Spots (LL): 324 tracts</p><p>- DATA QUALITY NOTES:</p><p>- Total census tracts: 2225</p><p>- Missing data rate: 0.0%</p><p>- MEDIAN_INCOME contains 25 placeholder values (coded as negative).</p></div>
</div></div>

<div class="notebook-section" id="notebook-07_ols_ml">
    <h3 class="notebook-title">8. OLS &amp; ML Modeling with SHAP</h3>
    <p class="notebook-description">OLS regression, Random Forest modeling, and SHAP interpretability analysis.</p>
    <div class="notebook-cells">

<div class="cell-markdown"><p><h4>Load the Data</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 1</summary>
        <pre class="cell-code"><code>import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score, mean_squared_error

import matplotlib.pyplot as plt
import numpy as np
import os</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 2</summary>
        <pre class="cell-code"><code>df = pd.read_csv(&quot;data/model/Final_Data_Model.csv&quot;)</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 3</summary>
        <pre class="cell-code"><code>df.shape</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">(2225, 20)</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 4</summary>
        <pre class="cell-code"><code># Socioeconomic and demographic predictors.
acs_predictors = [
    &quot;PCT_BACHELORS_PLUS&quot;,
    &quot;PCT_RENTERS&quot;,
    &quot;PCT_LIMITED_ENGLISH&quot;,
    &quot;MEDIAN_INCOME&quot;,
    &quot;POVERTY_RATE&quot;,
    &quot;PCT_NON_WHITE&quot;
]

# Environmental predictors.
env_predictors = [
    &quot;PCT_TREE_CANOPY&quot;,
    &quot;PCT_IMPERVIOUS&quot;,
    &quot;WCR&quot;,
    &quot;NDVI&quot;
]

# Urban form predictors.
# Parks were HIGHLY correlated to subway.
urban_predictors = [
    &quot;BD&quot;,   # Building density.
    &quot;AH&quot;,   # Weighted Average building height.
    &quot;POI_500M_DENSITY&quot;, # Spatial feature
    &quot;KNN_SUBWAY_dist_mean&quot;
]

# Combined predictor set with all features.
all_predictors = env_predictors + acs_predictors + urban_predictors

# 2 targets
targets = [&quot;heatweek_calls_per_1k&quot;, &quot;normalweek_calls_per_1k&quot;]</code></pre>
    </details>
    
</div>

<div class="cell-markdown"><p><h4>Data Cleaning</h4></p></div>
<div class="cell-markdown"><p><h5>Population Distribution</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 5</summary>
        <pre class="cell-code"><code>df[&quot;TOTAL_POP_x&quot;].hist(bins=40, figsize=(6,4))
plt.xlabel(&quot;KTOTAL_POP&quot;)
plt.ylabel(&quot;Count&quot;)
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>Targets Distribuiton</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 6</summary>
        <pre class="cell-code"><code>## Histogram
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Plot histograms
plt.figure(figsize=(12, 5))

# Histogram for heatweek_calls_per_1k
plt.subplot(1, 2, 1)
plt.hist(df[&quot;heatweek_calls_per_1k&quot;], bins=200)
plt.xlabel(&quot;Calls per 1k Population&quot;)
plt.ylabel(&quot;Frequency&quot;)

# Histogram for normalweek_calls_per_1k
plt.subplot(1, 2, 2)
plt.hist(df[&quot;normalweek_calls_per_1k&quot;], bins=200)
plt.title(&quot;Histogram of Normal Week Calls per 1k&quot;)
plt.xlabel(&quot;Calls per 1k Population&quot;)
plt.ylabel(&quot;Frequency&quot;)

plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>Log Transform</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 7</summary>
        <pre class="cell-code"><code>## Log Transformation for Targets

# Plot histograms
plt.figure(figsize=(12, 5))

# Histogram for heatweek_calls_per_1k
plt.subplot(1, 2, 1)
plt.hist(np.log1p(df[&quot;heatweek_calls_per_1k&quot;]), bins=100)
plt.xlabel(&quot;Logged Calls per 1k Population&quot;)
plt.ylabel(&quot;Frequency&quot;)

# Histogram for normalweek_calls_per_1k
plt.subplot(1, 2, 2)
plt.hist(np.log1p(df[&quot;normalweek_calls_per_1k&quot;]), bins=100)
plt.title(&quot;Histogram of Normal Week Calls per 1k&quot;)
plt.xlabel(&quot;Logged Calls per 1k Population&quot;)
plt.ylabel(&quot;Frequency&quot;)

plt.tight_layout()
plt.show()
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p><h5>Clean the data with MEDIAN_INCOME < 0, and Total Tract Population < 500.</h5></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 8</summary>
        <pre class="cell-code"><code>df = df[df[&quot;MEDIAN_INCOME&quot;] &gt; 0]
df = df[df[&quot;TOTAL_POP_x&quot;] &gt; 500]
df.shape</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-text">(2192, 20)</pre>
</div>
</div>

<div class="cell-markdown"><p><h4>OLS</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 9</summary>
        <pre class="cell-code"><code>pd.set_option(&quot;display.max_rows&quot;, None)
pd.set_option(&quot;display.max_columns&quot;, None)
pd.set_option(&quot;display.width&quot;, 2000)

</code></pre>
    </details>
    
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 10</summary>
        <pre class="cell-code"><code>import statsmodels.api as sm


X = df[all_predictors]
X = (X - X.mean()) / X.std() ## Standardize features
# y = df[&quot;heatweek_calls_per_1k&quot;]  
y = np.log1p(df[&quot;heatweek_calls_per_1k&quot;])

X_const = sm.add_constant(X)
ols_sm = sm.OLS(y, X_const).fit()

print(ols_sm.summary())  
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">                              OLS Regression Results                             
=================================================================================
Dep. Variable:     heatweek_calls_per_1k   R-squared:                       0.088
Model:                               OLS   Adj. R-squared:                  0.082
Method:                    Least Squares   F-statistic:                     14.94
Date:                   Mon, 01 Dec 2025   Prob (F-statistic):           4.79e-35
Time:                           16:06:38   Log-Likelihood:                -1453.7
No. Observations:                   2192   AIC:                             2937.
Df Residuals:                       2177   BIC:                             3023.
Df Model:                             14                                         
Covariance Type:               nonrobust                                         
========================================================================================
         
... [truncated]</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 11</summary>
        <pre class="cell-code"><code>X = df[all_predictors]
X = (X - X.mean()) / X.std() ## Standardize features
# y = df[&quot;normalweek_calls_per_1k&quot;]  
y = np.log1p(df[&quot;normalweek_calls_per_1k&quot;])

X_const = sm.add_constant(X)
ols_sm = sm.OLS(y, X_const).fit()

print(ols_sm.summary()) </code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">                               OLS Regression Results                              
===================================================================================
Dep. Variable:     normalweek_calls_per_1k   R-squared:                       0.084
Model:                                 OLS   Adj. R-squared:                  0.078
Method:                      Least Squares   F-statistic:                     14.22
Date:                     Mon, 01 Dec 2025   Prob (F-statistic):           3.78e-33
Time:                             16:06:40   Log-Likelihood:                -1379.4
No. Observations:                     2192   AIC:                             2789.
Df Residuals:                         2177   BIC:                             2874.
Df Model:                               14                                         
Covariance Type:                 nonrobust                                         
============================================================================
... [truncated]</pre>
</div>
</div>

<div class="cell-markdown"><p><h4>RF Model</h4></p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 12</summary>
        <pre class="cell-code"><code>from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import numpy as np
from tqdm.auto import tqdm

# ! pip install shap</code></pre>
    </details>
    
</div>

<div class="cell-markdown"><p>#### Heatweek Model</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 13</summary>
        <pre class="cell-code"><code># 1. Choose which target to model
target = &quot;heatweek_calls_per_1k&quot;  # 

# Log-transform the target to reduce skewness
df[target] = np.log1p(df[target])

X = df[all_predictors]
y = df[target]

# 2. Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

# 3. Define RF pipeline (no scaler)
rf_pipeline = Pipeline([
    (&quot;rf&quot;, RandomForestRegressor(random_state=42, n_jobs=-1))
])

# 4. Hyperparameter grid (small, reasonable ranges)
param_grid = {
    &quot;rf__n_estimators&quot;: [200, 400, 600],
    &quot;rf__max_depth&quot;: [10, 20, 30],
    &quot;rf__min_samples_split&quot;: [2, 5, 10],
    &quot;rf__min_samples_leaf&quot;: [1, 2, 4],
    &quot;rf__max_features&quot;: [&quot;auto&quot;, &quot;sqrt&quot;, 0.5],
}

# 5. GridSearchCV with 3-fold CV, optimizing RMSE
grid = GridSearchCV(
    estimator=rf_pipeline,
    param_grid=param_grid,
    cv=3,
    # scoring=&quot;r2&quot;,  # use r2 to find the most fit model for explanation
    scoring=&quot;neg_root_mean_squared_error&quot;,  # sklearn uses negative for losses 
    n_jobs=-1,
    verbose=2
)

# 6. Fit on training data
grid.fit(X_train, y_train)

print(&quot;Best parameters:&quot;, grid.best_params_)
print(&quot;Best CV RMSE:&quot;, -grid.best_score_)

# 7. Evaluate on test data using best model
best_rf_pipeline = grid.best_estimator_

y_pred_test = best_rf_pipeline.predict(X_test)

r2_test = r2_score(y_test, y_pred_test)
rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)
mae_test = mean_absolute_error(y_test, y_pred_test)

print(&quot;\n=== Test set performance (Random Forest) ===&quot;)
print(f&quot;RÂ² (test):   {r2_test:.4f}&quot;)
print(f&quot;RMSE (test): {rmse_test:.4f}&quot;)
print(f&quot;MAE (test):  {mae_test:.4f}&quot;)
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Fitting 3 folds for each of 243 candidates, totalling 729 fits
</pre>
<pre class="output-stream">c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\model_selection\_validation.py:425: FitFailedWarning: 
243 fits failed out of a total of 729.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score=&#x27;raise&#x27;.

Below are more details about the failures:
--------------------------------------------------------------------------------
80 fits failed with the following error:
Traceback (most recent call last):
  File &quot;c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\model_selection\_validation.py&quot;, line 732, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &quot;c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\base.py&quot;, line 1151, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File &quot;c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\pipeline.py&quot;, line 420, in fit
    self._final_estimator.fit(Xt,
... [truncated]</pre>
<pre class="output-stream">Best parameters: {&#x27;rf__max_depth&#x27;: 30, &#x27;rf__max_features&#x27;: 0.5, &#x27;rf__min_samples_leaf&#x27;: 4, &#x27;rf__min_samples_split&#x27;: 2, &#x27;rf__n_estimators&#x27;: 400}
Best CV RMSE: 0.4428078581968727

=== Test set performance (Random Forest) ===
RÂ² (test):   0.2458
RMSE (test): 0.4149
MAE (test):  0.3129
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 14</summary>
        <pre class="cell-code"><code>import shap
import matplotlib.pyplot as plt

# Initialize JS visualization (for notebooks)
shap.initjs()

# 1. Get the trained RandomForest model from the pipeline
rf_model = best_rf_pipeline.named_steps[&quot;rf&quot;]

# 2. Convert full dataset into numpy array
X_full = X.values    # full data (train + test)

# 3. Build SHAP explainer
explainer = shap.TreeExplainer(rf_model)

# 4. Compute SHAP values for test set
shap_values = explainer.shap_values(X_full)  # shape: (n_samples, n_features)

# 5. SHAP summary plot (beeswarm)
plt.figure(figsize=(10, 6))
shap.summary_plot(
    shap_values,
    X,
    feature_names=all_predictors,
    show=True
)

# 6. SHAP bar plot (mean |SHAP| value)
plt.figure(figsize=(8, 6))
shap.summary_plot(
    shap_values,
    X,
    feature_names=all_predictors,
    plot_type=&quot;bar&quot;,
    show=True
)
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-note">ðŸ“‹ <em>[Large table - see notebook for full output]</em></div>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>#### Percentage Feature Importance</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 15</summary>
        <pre class="cell-code"><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# shap_values: shape = (n_samples, n_features)
# all_predictors: list of feature names

# 1. Compute mean absolute SHAP importance for each feature
mean_abs_shap = np.mean(np.abs(shap_values), axis=0)

# 2. Put into DataFrame for easy plotting
shap_df = pd.DataFrame({
    &quot;feature&quot;: all_predictors,
    &quot;importance&quot;: mean_abs_shap
})

# 3. Sort by importance descending
shap_df = shap_df.sort_values(&quot;importance&quot;, ascending=False)

# 4. Compute percentage contribution
shap_df[&quot;percentage&quot;] = shap_df[&quot;importance&quot;] / shap_df[&quot;importance&quot;].sum() * 100

# 5. Plot bar chart with percentage label
plt.figure(figsize=(10, 6))
bars = plt.barh(shap_df[&quot;feature&quot;], shap_df[&quot;importance&quot;], color=&quot;steelblue&quot;)

plt.xlabel(&quot;Mean |SHAP value|&quot;, fontsize=12)
plt.title(&quot;SHAP Feature Importance (with percentage)&quot;, fontsize=14)

# 6. Add percentage labels to each bar
for i, (value, pct) in enumerate(zip(shap_df[&quot;importance&quot;], shap_df[&quot;percentage&quot;])):
    plt.text(
        value + shap_df[&quot;importance&quot;].max() * 0.01,  # small offset
        i,
        f&quot;{pct:.1f}%&quot;,
        va=&quot;center&quot;,
        fontsize=10
    )

plt.gca().invert_yaxis()  # highest at top
plt.tight_layout()
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>#### SHAP Plot for Feature of interest</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 16</summary>
        <pre class="cell-code"><code>import matplotlib.pyplot as plt

feature = &quot;PCT_IMPERVIOUS&quot;     #
idx = all_predictors.index(feature)  

plt.figure(figsize=(8,6))
plt.scatter(
    X[feature],         
    shap_values[:, idx],     
    alpha=0.4
)

plt.xlabel(feature)
plt.ylabel(f&quot;SHAP value for {feature}&quot;)
plt.title(f&quot;SHAP Scatter Plot for {feature}&quot;)
plt.grid(True)
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>#### Print and Save SHAP Scatter Plots for all features</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 17</summary>
        <pre class="cell-code"><code># Directory where the SHAP scatter plots will be saved
save_dir = &quot;images/SHAP2/shap_scatter_plots_heat&quot;
os.makedirs(save_dir, exist_ok=True)

# Loop through each predictor to generate SHAP scatter plots
for feature in all_predictors:

    # Get the column index of the current feature in the SHAP values array
    idx = all_predictors.index(feature)

    # Create the scatter plot
    plt.figure(figsize=(8, 6))
    plt.scatter(
        X[feature],          # Raw feature values (global: train + test recommended)
        shap_values[:, idx], # Corresponding SHAP values
        alpha=0.45
    )

    # Axis labels and title
    plt.xlabel(feature, fontsize=12)
    plt.ylabel(f&quot;SHAP value for {feature}&quot;, fontsize=12)
    plt.title(f&quot;SHAP Scatter Plot for {feature}&quot;, fontsize=14)
    plt.grid(True)

    # Create a safe filename (avoid illegal characters)
    safe_name = feature.replace(&quot;/&quot;, &quot;_&quot;).replace(&quot; &quot;, &quot;_&quot;)
    filepath = os.path.join(save_dir, f&quot;{safe_name}.png&quot;)

    # Save the figure
    plt.savefig(filepath, dpi=200, bbox_inches=&quot;tight&quot;)
    plt.close()

print(&quot;âœ“ All SHAP scatter plots have been saved to:&quot;, save_dir)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">âœ“ All SHAP scatter plots have been saved to: images/SHAP2/shap_scatter_plots_heat
</pre>
</div>
</div>

<div class="cell-markdown"><p>#### Regular heat week model</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 18</summary>
        <pre class="cell-code"><code># 1. Choose which target to model
target2 = &quot;normalweek_calls_per_1k&quot;  

# Log-transform the target to reduce skewness
df[target2] = np.log1p(df[target2])

X = df[all_predictors]
y = df[target2]

# 2. Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

# 3. Define RF pipeline (no scaler)
rf_pipeline = Pipeline([
    (&quot;rf&quot;, RandomForestRegressor(random_state=42, n_jobs=-1))
])

# 4. Hyperparameter grid 
param_grid = {
    &quot;rf__n_estimators&quot;: [200, 400, 600],
    &quot;rf__max_depth&quot;: [10, 20, 30],
    &quot;rf__min_samples_split&quot;: [2, 5, 10],
    &quot;rf__min_samples_leaf&quot;: [1, 2, 4],
    &quot;rf__max_features&quot;: [&quot;auto&quot;, &quot;sqrt&quot;, 0.5],
}

# 5. GridSearchCV with 3-fold CV, optimizing RMSE
grid = GridSearchCV(
    estimator=rf_pipeline,
    param_grid=param_grid,
    cv=3,
    ## scoring=&quot;r2&quot;, 
    scoring=&quot;neg_root_mean_squared_error&quot;,  # sklearn uses negative for losses 
    n_jobs=-1,
    verbose=2
)

# 6. Fit on training data
grid.fit(X_train, y_train)

print(&quot;Best parameters:&quot;, grid.best_params_)
print(&quot;Best CV RMSE:&quot;, -grid.best_score_)

# 7. Evaluate on test data using best model
best_rf_pipeline2 = grid.best_estimator_

y_pred_test = best_rf_pipeline2.predict(X_test)

r2_test = r2_score(y_test, y_pred_test)
rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)
mae_test = mean_absolute_error(y_test, y_pred_test)

print(&quot;\n=== Test set performance (Random Forest) ===&quot;)
print(f&quot;RÂ² (test):   {r2_test:.4f}&quot;)
print(f&quot;RMSE (test): {rmse_test:.4f}&quot;)
print(f&quot;MAE (test):  {mae_test:.4f}&quot;)
</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">Fitting 3 folds for each of 243 candidates, totalling 729 fits
</pre>
<pre class="output-stream">c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\model_selection\_validation.py:425: FitFailedWarning: 
243 fits failed out of a total of 729.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score=&#x27;raise&#x27;.

Below are more details about the failures:
--------------------------------------------------------------------------------
141 fits failed with the following error:
Traceback (most recent call last):
  File &quot;c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\model_selection\_validation.py&quot;, line 732, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &quot;c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\base.py&quot;, line 1151, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File &quot;c:\Users\DZM\.conda\envs\geospatial\lib\site-packages\sklearn\pipeline.py&quot;, line 420, in fit
    self._final_estimator.fit(Xt
... [truncated]</pre>
<pre class="output-stream">Best parameters: {&#x27;rf__max_depth&#x27;: 30, &#x27;rf__max_features&#x27;: 0.5, &#x27;rf__min_samples_leaf&#x27;: 4, &#x27;rf__min_samples_split&#x27;: 2, &#x27;rf__n_estimators&#x27;: 600}
Best CV RMSE: 0.21015411387026253

=== Test set performance (Random Forest) ===
RÂ² (test):   0.2738
RMSE (test): 0.1940
MAE (test):  0.1537
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 19</summary>
        <pre class="cell-code"><code>import shap
import matplotlib.pyplot as plt

# Initialize JS visualization (for notebooks)
shap.initjs()

# 1. Get the trained RandomForest model from the pipeline
rf_model2 = best_rf_pipeline2.named_steps[&quot;rf&quot;]

# 2. Use training data as background for SHAP
X_full = X.values  # TreeExplainer can work with numpy arrays

# 3. Build SHAP explainer
explainer = shap.TreeExplainer(rf_model2)

# 4. Compute SHAP values for test set
shap_values = explainer.shap_values(X_full)  # shape: (n_samples, n_features)

# 5. SHAP summary plot (beeswarm)
plt.figure(figsize=(10, 6))
shap.summary_plot(
    shap_values,
    X,
    feature_names=all_predictors,
    show=True
)

# 6. SHAP bar plot (mean |SHAP| value)
plt.figure(figsize=(8, 6))
shap.summary_plot(
    shap_values,
    X,
    feature_names=all_predictors,
    plot_type=&quot;bar&quot;,
    show=True
)
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-note">ðŸ“‹ <em>[Large table - see notebook for full output]</em></div>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>#### Percentage Feature Importance</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 20</summary>
        <pre class="cell-code"><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# shap_values: shape = (n_samples, n_features)
# all_predictors: list of feature names

# 1. Compute mean absolute SHAP importance for each feature
mean_abs_shap = np.mean(np.abs(shap_values), axis=0)

# 2. Put into DataFrame for easy plotting
shap_df = pd.DataFrame({
    &quot;feature&quot;: all_predictors,
    &quot;importance&quot;: mean_abs_shap
})

# 3. Sort by importance descending
shap_df = shap_df.sort_values(&quot;importance&quot;, ascending=False)

# 4. Compute percentage contribution
shap_df[&quot;percentage&quot;] = shap_df[&quot;importance&quot;] / shap_df[&quot;importance&quot;].sum() * 100

# 5. Plot bar chart with percentage label
plt.figure(figsize=(10, 6))
bars = plt.barh(shap_df[&quot;feature&quot;], shap_df[&quot;importance&quot;], color=&quot;steelblue&quot;)

plt.xlabel(&quot;Mean |SHAP value|&quot;, fontsize=12)
plt.title(&quot;SHAP Feature Importance (with percentage) for Regular Heat Model&quot;, fontsize=14)

# 6. Add percentage labels to each bar
for i, (value, pct) in enumerate(zip(shap_df[&quot;importance&quot;], shap_df[&quot;percentage&quot;])):
    plt.text(
        value + shap_df[&quot;importance&quot;].max() * 0.01,  # small offset
        i,
        f&quot;{pct:.1f}%&quot;,
        va=&quot;center&quot;,
        fontsize=10
    )

plt.gca().invert_yaxis()  # highest at top
plt.tight_layout()
plt.show()
</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

<div class="cell-markdown"><p>#### Print and Save SHAP Scatter Plots for all features</p></div>

<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 21</summary>
        <pre class="cell-code"><code># Directory where the SHAP scatter plots will be saved
save_dir = &quot;images/SHAP2/shap_scatter_plots_regular&quot;
os.makedirs(save_dir, exist_ok=True)

# Loop through each predictor to generate SHAP scatter plots
for feature in all_predictors:

    # Get the column index of the current feature in the SHAP values array
    idx = all_predictors.index(feature)

    # Create the scatter plot
    plt.figure(figsize=(8, 6))
    plt.scatter(
        X[feature],          # Raw feature values (global: train + test recommended)
        shap_values[:, idx], # Corresponding SHAP values
        alpha=0.45
    )

    # Axis labels and title
    plt.xlabel(feature, fontsize=12)
    plt.ylabel(f&quot;SHAP value for {feature}&quot;, fontsize=12)
    plt.title(f&quot;SHAP Scatter Plot for {feature}&quot;, fontsize=14)
    plt.grid(True)

    # Create a safe filename (avoid illegal characters)
    safe_name = feature.replace(&quot;/&quot;, &quot;_&quot;).replace(&quot; &quot;, &quot;_&quot;)
    filepath = os.path.join(save_dir, f&quot;{safe_name}.png&quot;)

    # Save the figure
    plt.savefig(filepath, dpi=200, bbox_inches=&quot;tight&quot;)
    plt.close()

print(&quot;âœ“ All SHAP scatter plots have been saved to:&quot;, save_dir)</code></pre>
    </details>
    <div class="cell-outputs">
<pre class="output-stream">âœ“ All SHAP scatter plots have been saved to: images/SHAP2/shap_scatter_plots_regular
</pre>
</div>
</div>


<div class="cell-code-wrapper">
    <details class="code-fold">
        <summary class="code-fold-toggle">Code Cell 22</summary>
        <pre class="cell-code"><code>import matplotlib.pyplot as plt

feature = &quot;BD&quot;     #
idx = all_predictors.index(feature)  

plt.figure(figsize=(8,6))
plt.scatter(
    X[feature],         
    shap_values[:, idx],     
    alpha=0.4
)

plt.xlabel(feature)
plt.ylabel(f&quot;SHAP value for {feature}&quot;)
plt.title(f&quot;SHAP Scatter Plot for {feature}&quot;)
plt.grid(True)
plt.show()</code></pre>
    </details>
    <div class="cell-outputs">
<div class="output-figure-placeholder">ðŸ“Š <em>[Figure output - see notebook]</em></div>
</div>
</div>

</div></div>
    </div>
</div>

<div class="content-right">
    <div class="panel-right-content">
        <h2>Notebooks</h2>
        <ul class="notebook-toc"><li><a href="#notebook-01a_weather_station_data_filtering">1a. Weather Station Data Filtering</a></li>
<li><a href="#notebook-01b_extreme_heat_days_filter">1b. Extreme Heat Days Classification</a></li>
<li><a href="#notebook-02_311_tract_daily">2. NYC 311 Data Processing</a></li>
<li><a href="#notebook-03_acs_tract">3. Census ACS Data</a></li>
<li><a href="#notebook-04_additional_feature">4. Additional Features</a></li>
<li><a href="#notebook-05_nlcd_calculations">5. NLCD Raster Calculations</a></li>
<li><a href="#notebook-06_data_merge_cleaning">6. Data Merging &amp; Cleaning</a></li>
<li><a href="#notebook-eda">7. Exploratory Data Analysis</a></li>
<li><a href="#notebook-07_ols_ml">8. OLS &amp; ML Modeling with SHAP</a></li></ul>
        
        <h2>About</h2>
        <p>These notebooks document the complete data pipeline from raw data acquisition through final SHAP analysis.</p>
        <p>Click "Show Code" to reveal individual code cells, or use the buttons to toggle all code at once.</p>
        <p><em>Figures and large outputs are shown as placeholders. View the original notebooks on GitHub for full visualizations.</em></p>
    </div>
    <div class="panel-right-footer">
        <h5>Data Pipeline</h5>
        <p>Weather â†’ 311 â†’ Census â†’ Features â†’ Merge â†’ EDA â†’ Modeling</p>
    </div>
</div>